{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# Opening JSON file\n",
    "f = open('/home/ferdinand_t/data/CMS_2010_to_June_2022_ENGLISH.json')\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firstKeyword'] = df['keywords'].apply(lambda x: x[0]['name'] if len(x) != 0 else None)\n",
    "# #df['secondKeyword'] = df['keywords'].apply(lambda x: x[1]['name'] if len(x) > 1 else None)\n",
    "# #df['thirdKeyword'] = df['keywords'].apply(lambda x: x[2]['name'] if len(x) > 2 else None)\n",
    "# #df['fourthKeyword'] = df['keywords'].apply(lambda x: x[3]['name'] if len(x) > 3 else None)\n",
    "\n",
    "df['cleanFocusCategory'] = df['thematicFocusCategory'].apply(lambda x: x['name'] if x is not None else x)\n",
    "\n",
    "# #df = df[['firstKeyword', 'secondKeyword', 'thirdKeyword', 'fourthKeyword', 'thematicFocusCategory', 'cleanFocusCategory']]\n",
    "\n",
    "df = df[['firstKeyword', 'keywordStrings', 'cleanFocusCategory']]\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.dropna()\n",
    "# df_clean['cleanKeywordStrings'] = [' '.join(map(str, l)) for l in df_clean['keywordStrings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"/home/ferdinand_t/Downloads/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53541, 31881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>08</th>\n",
       "      <th>0rg</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>özil</th>\n",
       "      <th>özlem</th>\n",
       "      <th>özoguz</th>\n",
       "      <th>øystein</th>\n",
       "      <th>út</th>\n",
       "      <th>überall</th>\n",
       "      <th>ünal</th>\n",
       "      <th>ünker</th>\n",
       "      <th>żurek</th>\n",
       "      <th>cleanFocusCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Conflicts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Conflicts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Conflicts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  007  01  03  04  05  08  0rg  10  100  ...  özil  özlem  özoguz  \\\n",
       "0    0    0   0   0   0   0   0    0   0    0  ...     0      0       0   \n",
       "1    0    0   0   0   0   0   0    0   0    0  ...     0      0       0   \n",
       "2    0    0   0   0   0   0   0    0   0    0  ...     0      0       0   \n",
       "3    0    0   0   0   0   0   0    0   0    0  ...     0      0       0   \n",
       "4    0    0   0   0   0   0   0    0   0    0  ...     0      0       0   \n",
       "\n",
       "   øystein  út  überall  ünal  ünker  żurek  cleanFocusCategory  \n",
       "0        0   0        0     0      0      0           Conflicts  \n",
       "1        0   0        0     0      0      0           Conflicts  \n",
       "2        0   0        0     0      0      0            Politics  \n",
       "3        0   0        0     0      0      0            Politics  \n",
       "4        0   0        0     0      0      0           Conflicts  \n",
       "\n",
       "[5 rows x 31881 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "corpus_train, corpus_test, label_train, label_test, indices_train, indices_test = train_test_split(df_clean['keywordStrings'], df_clean['cleanFocusCategory'].astype(str), df_clean.index, test_size=0.33, random_state=0) \n",
    "# Ticket Data\n",
    "corpus = corpus_train.astype(str)\n",
    " \n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1),stop_words='english')\n",
    " \n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "#print(vectorizer.get_feature_names())\n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "CountVectorizedData['cleanFocusCategory']=label_train.values\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsVocab=CountVectorizedData.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_corpus_train = vectorizer.transform(corpus_train.astype(str))\n",
    "CountVecData=pd.DataFrame(X_corpus_train.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "W2Vec_Data_temp=pd.DataFrame()\n",
    "    \n",
    "Sentence_1=[[wv[word] if word in wv.key_to_index.keys() else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_1))\n",
    "Sentence_2=[[wv[word.capitalize()] if word.capitalize() in wv.key_to_index.keys() and word not in wv.key_to_index.keys()  else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_2))\n",
    "test_sum_df = W2Vec_Data_temp.groupby(W2Vec_Data_temp.index).sum()\n",
    "#W2Vec_Data = test_sum_df.sum(axis=1)\n",
    "test_sum_df[test_sum_df.applymap(lambda x: np.allclose(x, 0))] = np.nan\n",
    "W2Vec_Data = test_sum_df.apply(lambda x: np.mean(x[x.notnull()]), axis=1)\n",
    "W2Vec_Data_df = pd.DataFrame(W2Vec_Data)\n",
    "W2Vec_Data_df_final = W2Vec_Data_df[0].apply(pd.Series)\n",
    "W2Vec_Data_corpus_train = W2Vec_Data_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53541, 301)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO THEN I DONT HAVE TO CREATE THE DATAFRAME BEFORE THAT STEP\n",
    "# Adding the target variable\n",
    "W2Vec_Data_corpus_train.reset_index(inplace=True, drop=True)\n",
    "W2Vec_Data_corpus_train['cleanFocusCategory']=label_train.values\n",
    " \n",
    "# Assigning to DataForML variable\n",
    "DataForML_corpus_train=W2Vec_Data_corpus_train\n",
    "DataForML_corpus_train.loc[DataForML_corpus_train.isna().any(axis=1),0:299] = 0\n",
    "DataForML_corpus_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable_corpus_train=DataForML_corpus_train.columns[-1]\n",
    "Predictors_corpus_train=DataForML_corpus_train.columns[:-1]\n",
    " \n",
    "X_corpus_train=DataForML_corpus_train[Predictors_corpus_train].values\n",
    "y_corpus_train=DataForML_corpus_train[TargetVariable_corpus_train].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = vectorizer.transform(corpus_test.astype(str))\n",
    "CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "W2Vec_Data_temp=pd.DataFrame()\n",
    "    \n",
    "Sentence_1=[[wv[word] if word in wv.key_to_index.keys() else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_1))\n",
    "Sentence_2=[[wv[word.capitalize()] if word.capitalize() in wv.key_to_index.keys() and word not in wv.key_to_index.keys()  else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_2))\n",
    "test_sum_df = W2Vec_Data_temp.groupby(W2Vec_Data_temp.index).sum()\n",
    "#W2Vec_Data = test_sum_df.sum(axis=1)\n",
    "test_sum_df[test_sum_df.applymap(lambda x: np.allclose(x, 0))] = np.nan\n",
    "W2Vec_Data = test_sum_df.apply(lambda x: np.mean(x[x.notnull()]), axis=1)\n",
    "W2Vec_Data_df = pd.DataFrame(W2Vec_Data)\n",
    "W2Vec_Data_df_final = W2Vec_Data_df[0].apply(pd.Series)\n",
    "W2Vec_Data = W2Vec_Data_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26372, 301)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO THEN I DONT HAVE TO CREATE THE DATAFRAME BEFORE THAT STEP\n",
    "# Adding the target variable\n",
    "W2Vec_Data.reset_index(inplace=True, drop=True)\n",
    "W2Vec_Data['cleanFocusCategory']=label_test.values\n",
    " \n",
    "# Assigning to DataForML variable\n",
    "DataForML=W2Vec_Data\n",
    "DataForML.loc[DataForML.isna().any(axis=1),0:299] = 0\n",
    "DataForML.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=DataForML.columns[-1]\n",
    "Predictors=DataForML.columns[:-1]\n",
    " \n",
    "X=DataForML[Predictors].values\n",
    "y=DataForML[TargetVariable].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19779, 300)\n",
      "(19779,)\n",
      "(6593, 300)\n",
      "(6593,)\n"
     ]
    }
   ],
   "source": [
    "# # Split the data into training and testing set\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494387987259215"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_corpus_train, y_corpus_train)\n",
    "y_pred = model.predict(X)\n",
    "accuracy_score(y,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
