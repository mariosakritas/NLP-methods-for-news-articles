{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext\n",
    "\n",
    "following tutorial https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- prepare an input file with categories and their keywords\n",
    "- prepare input file with categories and single keywords\n",
    "- split datasets in training and validation\n",
    "- run simple model settings (default as above)\n",
    "- balance datasets for training \n",
    " - feed GOOOGLE search words!\n",
    "\n",
    " \n",
    "- try to use it as a word vectorizer and measure distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "Loading data DONE. Number of articles is 175659\n",
      "Extracting data DONE. Number of articles from 2017-01-01 to 2022-01-01 is 69432\n"
     ]
    }
   ],
   "source": [
    "## load the data\n",
    "import sys\n",
    "# Add src folder to the path\n",
    "sys.path.append('../src/')\n",
    "from data.preprocess_keywords import make_cleaned_keywords_df\n",
    "from data.make_datasets import get_data\n",
    "# Specify wanted time range\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2022-01-01'\n",
    "# Path to data\n",
    "data_file = '/home/anya_m/data/dw-project-data/CMS_2010_to_June_2022_ENGLISH.json'\n",
    "# Load and extract data within time range\n",
    "df_subset = get_data(data_file, start_date, end_date)\n",
    "# Cleans keywords and saves data as a dataframe\n",
    "#make_cleaned_keywords_df(df_subset, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DW data\n",
    "import pandas as pd\n",
    "start_date = '2017-01-01' #'2019-01-01' #'2021-01-01'\n",
    "end_date = '2022-01-01'\n",
    "filepath = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "df = pd.read_json(filepath, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column teaser to the df cleaned dataframe\n",
    "df=df.merge(df_subset['teaser'], left_on=df_subset['id'], right_on=df['id'])\n",
    "df=df.drop(['key_0'], axis=1)\n",
    "df=df.drop(['keywordStrings'], axis=1)\n",
    "#add column with full text of the article into the dataframe\n",
    "# df=df.merge(df_subset['text'], left_on=df['id'], right_on=df_subset['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == \"\":\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#remove all NaN fields\n",
    "df_clean=df.dropna(how='any')\n",
    "df_clean_copy = df_clean.copy(deep=True)\n",
    "##TODO\n",
    "#df_clean['cleanFocusCategory']=='Law and Justice' replace with Law-and-Justice  and other categories\n",
    "\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Law and Justice'], 'Law-and-Justice')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Nature and Environment'], 'Nature-and-Environment')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Human Rights'], 'Human-Rights')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Cars and Transportation'], 'Cars-and-Transportation')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Press Freedom'], 'Press-Freedom')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Digital World'], 'Digital-World')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Rule of Law'], 'Rule-of-Law')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Learning German'], 'Learning-German')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Freedom of Speech'], 'Freedom-of-Speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['History', 'Politics', 'Society', 'Culture', 'Media',\n",
       "       'Law-and-Justice', 'Catastrophe', 'Lifestyle', 'Business',\n",
       "       'Travel', 'Sports', 'Science', 'Health', 'Nature-and-Environment',\n",
       "       'Cars-and-Transportation', 'Education', 'Religion', 'Human-Rights',\n",
       "       'Technology', 'Learning-German', 'Digital-World', 'Migration',\n",
       "       'Offbeat', 'Innovation'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['cleanFocusCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_single_kw=df_clean.explode('keywordStringsCleanAfterFuzz')\n",
    "\n",
    "label=df_clean['cleanFocusCategory'].apply(lambda x: ('__label__' +x+' '))\n",
    "kw=df_clean['keywordStringsCleanAfterFuzz'].apply(lambda x: (', '.join(x)))\n",
    "teaser=df_clean['teaser']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_single_kw=df_clean_single_kw.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           __label__History margaret thatcher\n",
      "0                 __label__History helmut kohl\n",
      "0        __label__History german reunification\n",
      "0                 __label__History berlin wall\n",
      "0                     __label__History britain\n",
      "                         ...                  \n",
      "69431                   __label__Health france\n",
      "69431            __label__Health birth control\n",
      "69431            __label__Health contraception\n",
      "69431           __label__Health contraceptives\n",
      "69431      __label__Health reproductive health\n",
      "Length: 358724, dtype: object\n"
     ]
    }
   ],
   "source": [
    "single_kw_label=df_clean_single_kw['cleanFocusCategory'].apply(lambda x: ('__label__' +x+' '))\n",
    "single_kw=df_clean_single_kw['keywordStringsCleanAfterFuzz']\n",
    "print(single_kw_label+single_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(label+teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(label+kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_kw=label+kw\n",
    "label_single_kw=single_kw_label+single_kw\n",
    "label_teaser=label+teaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test subsets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "def split_dataset(dataset, label):\n",
    "    train_set, test_set=tts(dataset, random_state=0, test_size=0.33, stratify=label)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_kw_train,label_kw_test=split_dataset(label_kw,label)\n",
    "label_single_kw_train,label_single_kw_test=split_dataset(label_single_kw,single_kw_label)\n",
    "label_teaser_train,label_teaser_test=split_dataset(label_teaser,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save training/validation file for fasttext\n",
    "# #label+single keyword (all keywords using pd.explode)\n",
    "# from tqdm import tqdm\n",
    "# !rm ./fasttext/single_kw.txt\n",
    "# with open('./fasttext/single_kw.txt', 'a') as f:\n",
    "#     for i, el in tqdm(enumerate(single_kw_label)):\n",
    "#         #print(i)\n",
    "#         #print(kw[i])\n",
    "#         print(el+single_kw.iloc[i],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save training/validation file for fasttext\n",
    "# #label+teaser\n",
    "# from tqdm import tqdm\n",
    "# !rm ./fasttext/teaser.txt\n",
    "# with open('./fasttext/teaser.txt', 'a') as f:\n",
    "#     for i, el in tqdm(enumerate(label)):\n",
    "#         #print(i)\n",
    "#         #print(kw[i])\n",
    "#         print(el+teaser.iloc[i],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save training/validation file for fasttext\n",
    "# #label+all DW keywords\n",
    "# from tqdm import tqdm\n",
    "# !rm ./fasttext/output.txt\n",
    "# with open('./fasttext/output.txt', 'a') as f:\n",
    "#     for i, el in tqdm(enumerate(label)):\n",
    "#         #print(i)\n",
    "#         #print(kw[i])\n",
    "#         print(el+kw.iloc[i],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_txt(out_name,data_to_save):\n",
    "    from tqdm import tqdm\n",
    "    #!rm $out_name\n",
    "    if os.path.isfile(out_name):\n",
    "        os.remove(out_name)\n",
    "    with open(out_name,'a') as f:\n",
    "        for i,el in tqdm(enumerate(data_to_save)):\n",
    "            print(el,file=f)\n",
    "    input_file=out_name\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45882it [00:00, 259642.41it/s]\n",
      "22599it [00:00, 327278.58it/s]\n"
     ]
    }
   ],
   "source": [
    "all_kw_train=save_txt('./fasttext/all_kw_train.txt',label_kw_train)\n",
    "all_kw_test=save_txt('./fasttext/all_kw_test.txt',label_kw_test)\n",
    "#all_kw_train\n",
    "#!head ./fasttext/all_kw_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240345it [00:00, 659832.79it/s]\n",
      "118379it [00:00, 681208.92it/s]\n"
     ]
    }
   ],
   "source": [
    "single_kw_train=save_txt('./fasttext/single_kw_train.txt',label_single_kw_train)\n",
    "single_kw_test=save_txt('./fasttext/single_kw_test.txt',label_single_kw_test)\n",
    "\n",
    "!cat ./fasttext/single_kw_train.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/single_kw_train.preprocessed.txt\n",
    "!cat ./fasttext/single_kw_test.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/single_kw_test.preprocessed.txt\n",
    "\n",
    "single_kw_train_prec='./fasttext/single_kw_train.preprocessed.txt'\n",
    "single_kw_test_prec='./fasttext/single_kw_test.preprocessed.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45882it [00:00, 349900.28it/s]\n",
      "22599it [00:00, 432635.95it/s]\n"
     ]
    }
   ],
   "source": [
    "teaser_train=save_txt('./fasttext/teaser_train.txt',label_teaser_train)\n",
    "teaser_test=save_txt('./fasttext/teaser_test.txt',label_teaser_test)\n",
    "\n",
    "!cat ./fasttext/teaser_train.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/teaser_train.preprocessed.txt\n",
    "!cat ./fasttext/teaser_test.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/teaser_test.preprocessed.txt\n",
    "\n",
    "teaser_train_prec='./fasttext/teaser_train.preprocessed.txt'\n",
    "teaser_test_prec='./fasttext/teaser_test.preprocessed.txt'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Fasttext\n",
    "- DW all kw + DW cats  - training + validation\n",
    "- DW all kw for training, DW single kw for validation\n",
    "- DW single kw for training + validation\n",
    "- DW teaser + DW cats          - training + validation\n",
    "\n",
    "implement train_test_split for splitting dataset\n",
    "\n",
    "- DW teaser / kw for training , google for ???\n",
    "- - validation based on similarity of google to DW kw (rapidfuzz? cdist / word embeddings using fasstext)\n",
    "\n",
    "- - make graphics to compare categories from DW and Google\n",
    "\n",
    "- DW text for training, DW kw for validation\n",
    "- - clean html (beautiful soup?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing dataset into training and validation sets\n",
    "\n",
    "!head -n 50000 ./fasttext/output.txt > ./fasttext/output.train\n",
    "!tail -n 20000 ./fasttext/output.txt > ./fasttext/output.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing dataset into training and validation sets\n",
    "!cat ./fasttext/output.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/output.preprocessed.txt\n",
    "\n",
    "!head -n 50000 ./fasttext/output.preprocessed.txt > ./fasttext/output_cl.train\n",
    "!tail -n 20000 ./fasttext/output.preprocessed.txt > ./fasttext/output_cl.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single kw \n",
    "#preprocessing and \n",
    "#splittig into training and validation sets\n",
    "!cat ./fasttext/single_kw.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/single_kw.preprocessed.txt\n",
    "\n",
    "!head -n 300000 ./fasttext/single_kw.preprocessed.txt > ./fasttext/single_kw_cl.train\n",
    "!tail -n 60000 ./fasttext/single_kw.preprocessed.txt > ./fasttext/single_kw_cl.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_classifier(train_file,test_file,lr=1.0,epoch=12,k=1,wordNgrams=1):\n",
    "    model = fasttext.train_supervised(input=train_file, lr=lr, epoch=epoch)\n",
    "    #model.test(test_file,k=k)\n",
    "    print(model.test(test_file,k=1))\n",
    "    print(model.test(test_file,k=2))\n",
    "    print(model.test(test_file,k=3))\n",
    "    print(model.test(test_file,k=4))\n",
    "    print(model.test(test_file,k=5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  36772\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  437245 lr:  0.000000 avg.loss:  0.596297 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22599, 0.6906500287623346, 0.6906500287623346)\n",
      "(22599, 0.412717376875083, 0.825434753750166)\n",
      "(22599, 0.2952048025723852, 0.8856144077171556)\n",
      "(22599, 0.22936855613080226, 0.917474224523209)\n",
      "(22599, 0.1873180229213682, 0.936590114606841)\n"
     ]
    }
   ],
   "source": [
    "model_all_kw_check=fasttext_classifier(all_kw_train,all_kw_test,lr=0.7)\n",
    "#model_all_kw_check.test(all_kw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single_kw_check=fasttext_classifier(single_kw_train,single_kw_test,lr=0.7,wordNgrams=1)\n",
    "#model_single_kw_check.test(single_kw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single_kw_check=fasttext_classifier(single_kw_train,single_kw_test,lr=0.7,wordNgrams=5)\n",
    "#model_single_kw_check.test(single_kw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single_kw_check_prec=fasttext_classifier(single_kw_train_prec,single_kw_test_prec,lr=0.7)\n",
    "#model_single_kw_check_prec.test(single_kw_test_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teaser=fasttext_classifier(teaser_train,teaser_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teaser=fasttext_classifier(teaser_train_prec,teaser_test_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teaser_single=fasttext_classifier(teaser_train_prec,single_kw_test_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_all_single = fasttext.train_supervised(input=\"./fasttext/output.preprocessed.txt\", autotuneValidationFile=\"./fasttext/single_kw.preprocessed.txt\")\n",
    "model_best_all_single.test(\"./fasttext/single_kw.preprocessed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatic search for best hyperparameters https://fasttext.cc/docs/en/autotune.html \n",
    "#last 5 minutes\n",
    "train_file=\"./fasttext/single_kw_cl.train\"\n",
    "valid_file='./fasttext/single_kw_cl.valid'\n",
    "model_best_single = fasttext.train_supervised(input=train_file, autotuneValidationFile=valid_file)\n",
    "model_best_single.test(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatic search for best hyperparameters https://fasttext.cc/docs/en/autotune.html \n",
    "#last 5 minutes\n",
    "model_best = fasttext.train_supervised(input=train_file, autotuneValidationFile='./fasttext/output_cl.valid')\n",
    "model_best.test('./fasttext/output_cl.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output are the number of samples (here 14999), \n",
    "# the precision at one (0.6968)  69% and \n",
    "# the recall at one (0.0541).\n",
    "\n",
    "#The precision is the number of correct labels among the labels predicted by fastText. \n",
    "# The recall is the number of labels that successfully were predicted,\n",
    "# among all the real labels. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a few steps, we were able to go from a precision at one of 12.4% to 59.9%. Important steps included:\n",
    "\n",
    "- preprocessing the data ;\n",
    "- changing the number of epochs (using the option -epoch, standard range [5 - 50]) ;\n",
    "- changing the learning rate (using the option -lr, standard range [0.1 - 1.0]) ;\n",
    "- using word n-grams (using the option -wordNgrams, standard range [1 - 5])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with cleaned teaser tested on teaser\n",
    "train_file=\"./fasttext/teaser_cl.train\"\n",
    "model_file=\"./fasttext/model_teaser_cl_output.bin\"\n",
    "test_file=\"./fasttext/teaser_cl.valid\"\n",
    "\n",
    "model_teaser_cl = fasttext.train_supervised(input=train_file, lr=0.9, epoch=25)\n",
    "#saving the model\n",
    "model_teaser_cl.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_cl.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, epoch=12)\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, epoch=50, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, wordNgrams=5, epoch=50, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google keywords to dw categories\n",
    "# Load Google data\n",
    "df_google = pd.read_json('../data/interim/2021-daily-trending-searches.json', orient ='split', compression = 'infer')\n",
    "\n",
    "# Keeps only google data within DW data date range\n",
    "start_date_dw=start_date\n",
    "end_date_dw=end_date\n",
    "df_google.sort_values(by ='date', inplace = True) \n",
    "mask = (pd.to_datetime(df_google['date']) > start_date_dw) & (pd.to_datetime(df_google['date']) <= end_date_dw)\n",
    "df_google_subset = df_google.loc[mask].copy()\n",
    "google_topic=df_google_subset['topic_title']\n",
    "google_topic_type=df_google_subset['topic_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_subset.head()\n",
    "#interesting columns:\n",
    "# df_google_subset['topic_title']\n",
    "# df_google_subset['topic_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('__label__Culture', '__label__Law-and-Justice'), array([9.98319864e-01, 7.70073209e-04]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Law-and-Justice'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a table with predicted categories\n",
    "# column with a single predicted category\n",
    "selected_keyword='bowl game'\n",
    "\n",
    "x=(model_all_kw_check.predict(selected_keyword,k=2))\n",
    "\n",
    "\n",
    "\n",
    "#col_pred1=\n",
    "#column with two predicted categories\n",
    "#column with three predicted categories\n",
    "#column with four predicted categories\n",
    "#column with five predicted categories\n",
    "\n",
    "pred_label=x[0][0].split('__')[2]\n",
    "print(pred_label)\n",
    "pred_label2=x[0][1].split('__')[2]\n",
    "pred_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Law-and-Justice'), array([9.98319864e-01, 7.70073209e-04]))\"]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(x).split('__')[2].split('\\',')[:]\n",
    "str(x).split('__')[4].split('\\',')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Law-and-Justice'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1].split('__')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list comprehension : #[func(el) for el in my_list]\n",
    "def prediction(model, keyword,k=1):\n",
    "    x=model.predict(keyword,k=k)\n",
    "    pred_label=x[0][0].split('__')[2]\n",
    "    return pred_label\n",
    "\n",
    "\n",
    "pred_label=prediction(model_all_kw_check,selected_keyword,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "# df = pd.DataFrame(data=d)\n",
    "\n",
    "d={'dw_cat','dw_kw','pred_cat'}\n",
    "df_single=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skipgram model :\n",
    "# model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
    "\n",
    "# # or, cbow model :\n",
    "# model = fasttext.train_unsupervised('data.txt', model='cbow')\n",
    "\n",
    "\n",
    "# print(model.words)   # list of words in dictionary\n",
    "# print(model['king']) # get the vector of the word 'king'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
