{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext\n",
    "\n",
    "following tutorial https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc ./fasttext/cooking.stackexchange.txt\n",
    "#splitiing dataset into training and validation sets\n",
    "!head -n 12404 ./fasttext/cooking.stackexchange.txt > ./fasttext/cooking.train\n",
    "!tail -n 3000 ./fasttext/cooking.stackexchange.txt > ./fasttext/cooking.valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our first classifier\n",
    "model = fasttext.train_supervised(input=\"./fasttext/cooking.train\")\n",
    "#saving the model\n",
    "model.save_model(\"./fasttext/model_cooking.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"Which baking dish is best to bake a banana bread ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"Why not put knives in the dishwasher?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"./fasttext/cooking.valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(\"./fasttext/cooking.valid\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"Why not put knives in the dishwasher?\", k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- prepare an input file with categories and their keywords\n",
    "- split dataset in training and validation\n",
    "- run simple model settings (defaukt as above)\n",
    " - feed GOOOGLE search trands!\n",
    "\n",
    " \n",
    "- try to use it as a word vectorizer and measure distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data\n",
    "import sys\n",
    "# Add src folder to the path\n",
    "sys.path.append('../src/')\n",
    "from data.preprocess_keywords import make_cleaned_keywords_df\n",
    "from data.make_datasets import get_data\n",
    "# Specify wanted time range\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2022-01-01'\n",
    "# Path to data\n",
    "data_file = '/home/anya_m/data/dw-project-data/CMS_2010_to_June_2022_ENGLISH.json'\n",
    "# Load and extract data within time range\n",
    "df_subset = get_data(data_file, start_date, end_date)\n",
    "# Cleans keywords and saves data as a dataframe\n",
    "make_cleaned_keywords_df(df_subset, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DW data\n",
    "import pandas as pd\n",
    "start_date = '2017-01-01' #'2019-01-01' #'2021-01-01'\n",
    "end_date = '2022-01-01'\n",
    "filepath = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "df = pd.read_json(filepath, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "69432"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(len(df))\n",
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google data\n",
    "df_google = pd.read_json('../data/interim/2021-daily-trending-searches.json', orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only google data within DW data date range\n",
    "start_date_dw=start_date\n",
    "end_date_dw=end_date\n",
    "df_google.sort_values(by ='date', inplace = True) \n",
    "mask = (pd.to_datetime(df_google['date']) > start_date_dw) & (pd.to_datetime(df_google['date']) <= end_date_dw)\n",
    "df_google_subset = df_google.loc[mask].copy()\n",
    "google_topic=df_google_subset['topic_title']\n",
    "google_topic_type=df_google_subset['topic_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_google_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column teaser to the df cleaned dataframe\n",
    "df=df.merge(df_subset['teaser'], left_on=df_subset['id'], right_on=df['id'])\n",
    "df=df.drop(['key_0'], axis=1)\n",
    "df=df.merge(df_subset['text'], left_on=df['id'], right_on=df_subset['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69432 entries, 0 to 69431\n",
      "Data columns (total 6 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   id                            69432 non-null  int64         \n",
      " 1   lastModifiedDate              69432 non-null  object        \n",
      " 2   Date                          69432 non-null  datetime64[ns]\n",
      " 3   keywordStrings                69432 non-null  object        \n",
      " 4   keywordStringsCleanAfterFuzz  69432 non-null  object        \n",
      " 5   cleanFocusCategory            68481 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == \"\":\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_clean=df.dropna(how='any')\n",
    "df_clean_copy = df_clean.copy(deep=True)\n",
    "##TODO\n",
    "#df_clean['cleanFocusCategory']=='Law and Justice' replace with Law-and-Justice  and other categories\n",
    "\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Law and Justice'], 'Law-and-Justice')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Nature and Environment'], 'Nature-and-Environment')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Human Rights'], 'Human-Rights')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Cars and Transportation'], 'Cars-and-Transportation')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Press Freedom'], 'Press-Freedom')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Digital World'], 'Digital-World')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Rule of Law'], 'Rule-of-Law')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Learning German'], 'Learning-German')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Freedom of Speech'], 'Freedom-of-Speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['History', 'Politics', 'Society', 'Culture', 'Media',\n",
       "       'Law-and-Justice', 'Catastrophe', 'Lifestyle', 'Business',\n",
       "       'Travel', 'Sports', 'Science', 'Health', 'Nature-and-Environment',\n",
       "       'Cars-and-Transportation', 'Education', 'Religion', 'Human-Rights',\n",
       "       'Technology', 'Learning-German', 'Digital-World', 'Migration',\n",
       "       'Offbeat', 'Innovation'], dtype=object)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['cleanFocusCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=df_clean['cleanFocusCategory'].apply(lambda x: ('__label__' +x+' '))\n",
    "kw=df_clean['keywordStrings'].apply(lambda x: (', '.join(x)))\n",
    "teaser=df_clean['teaser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label+teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label+kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68481it [00:01, 50816.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "!rm ./fasttext/teaser.txt\n",
    "with open('./fasttext/teaser.txt', 'a') as f:\n",
    "    for i, el in tqdm(enumerate(label)):\n",
    "        #print(i)\n",
    "        #print(kw[i])\n",
    "        print(el+teaser.iloc[i],file=f)\n",
    "    \n",
    "    \n",
    "    #el.apply(lambda x: ' '.join(kw[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68481it [00:00, 71646.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "!rm ./fasttext/output.txt\n",
    "with open('./fasttext/output.txt', 'a') as f:\n",
    "    for i, el in tqdm(enumerate(label)):\n",
    "        #print(i)\n",
    "        #print(kw[i])\n",
    "        print(el+kw.iloc[i],file=f)\n",
    "    \n",
    "    \n",
    "    #el.apply(lambda x: ' '.join(kw[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Fasttext\n",
    "- DW keywords + DW categories  - training + validation\n",
    "- DW teaser + DW cats          - training + validation\n",
    "- DW teaser / keywords for training , google for prediction\n",
    "- - validation based on similarity of google to DW keywords (rapidfuzz? cdist / word embeddings)\n",
    "- - make graphics\n",
    "\n",
    "- DW text for training, google for prediction\n",
    "- - clean html (beautiful soup?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing dataset into training and validation sets\n",
    "\n",
    "!head -n 50000 ./fasttext/output.txt > ./fasttext/output.train\n",
    "!tail -n 20000 ./fasttext/output.txt > ./fasttext/output.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing dataset into training and validation sets\n",
    "!cat ./fasttext/output.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/output.preprocessed.txt\n",
    "\n",
    "!head -n 50000 ./fasttext/output.preprocessed.txt > ./fasttext/output_cl.train\n",
    "!tail -n 20000 ./fasttext/output.preprocessed.txt > ./fasttext/output_cl.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  46227\n",
      "Number of labels: 22\n",
      "Progress: 100.0% words/sec/thread:  445314 lr:  0.000000 avg.loss:  0.647694 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "#our first classifier\n",
    "train_file=\"./fasttext/output.train\"\n",
    "model = fasttext.train_supervised(input=train_file, lr=1.0, epoch=12)\n",
    "#saving the model\n",
    "model.save_model(\"./fasttext/model_output.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19964, 0.6350430775395712, 0.6350430775395712)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"./fasttext/output.valid\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  31769\n",
      "Number of labels: 22\n",
      "Progress: 100.0% words/sec/thread: 1760339 lr:  0.000000 avg.loss:  0.795935 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "!rm ./fasttext/model_cleaned_output.bin\n",
    "#our first classifier\n",
    "train_file=\"./fasttext/output_cl.train\"\n",
    "model_cleaned = fasttext.train_supervised(input=train_file, lr=1.0, epoch=12, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_cleaned.save_model(\"./fasttext/model_cleaned_output.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19964, 0.6430575035063114, 0.6430575035063114)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cleaned.test(\"./fasttext/output_cl.valid\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   23 Best score:  0.658736 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 0M words\n",
      "Number of words:  31769\n",
      "Number of labels: 22\n",
      "Progress: 100.0% words/sec/thread:  741156 lr:  0.000000 avg.loss:  0.837053 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "#automatic search for best hyperparameters https://fasttext.cc/docs/en/autotune.html \n",
    "model_best = fasttext.train_supervised(input=train_file, autotuneValidationFile='./fasttext/output_cl.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19964, 0.6515728310959727, 0.6515728310959727)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best.test('./fasttext/output_cl.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__Politics',\n",
       "  '__label__Culture',\n",
       "  '__label__Business',\n",
       "  '__label__Law-and-Justice',\n",
       "  '__label__Sports'),\n",
       " array([9.24510300e-01, 4.67729419e-02, 2.85993479e-02, 1.13516013e-04,\n",
       "        3.87617984e-05]))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"house\",k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__politics',\n",
       "  '__label__business',\n",
       "  '__label__culture',\n",
       "  '__label__travel',\n",
       "  '__label__lifestyle'),\n",
       " array([0.34492129, 0.27110988, 0.25599673, 0.07063578, 0.02948774]))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cleaned.predict(\"house\",k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output are the number of samples (here 14999), \n",
    "# the precision at one (0.6968)  69% and \n",
    "# the recall at one (0.0541).\n",
    "\n",
    "#The precision is the number of correct labels among the labels predicted by fastText. \n",
    "# The recall is the number of labels that successfully were predicted,\n",
    "# among all the real labels. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a few steps, we were able to go from a precision at one of 12.4% to 59.9%. Important steps included:\n",
    "\n",
    "- preprocessing the data ;\n",
    "- changing the number of epochs (using the option -epoch, standard range [5 - 50]) ;\n",
    "- changing the learning rate (using the option -lr, standard range [0.1 - 1.0]) ;\n",
    "- using word n-grams (using the option -wordNgrams, standard range [1 - 5])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(\"knives\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with uncleaned teaser \n",
    "\n",
    "#splitiing dataset into training and validation sets\n",
    "\n",
    "!head -n 50000 ./fasttext/teaser.txt > ./fasttext/teaser.train\n",
    "!tail -n 20000 ./fasttext/teaser.txt > ./fasttext/teaser.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  94005\n",
      "Number of labels: 22\n",
      "Progress: 100.0% words/sec/thread: 1001291 lr:  0.000000 avg.loss:  0.359905 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19927, 0.6028002208059416, 0.6028002208059416)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier\n",
    "train_file=\"./fasttext/teaser.train\"\n",
    "model_file=\"./fasttext/model_teaser_output.bin\"\n",
    "test_file=\"./fasttext/teaser.valid\"\n",
    "\n",
    "model_teaser = fasttext.train_supervised(input=train_file, lr=1.0, epoch=25)\n",
    "#saving the model\n",
    "model_teaser.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with cleaned teaser \n",
    "\n",
    "#splitiing dataset into training and validation sets\n",
    "\n",
    "!cat ./fasttext/teaser.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/teaser.preprocessed.txt\n",
    "\n",
    "!head -n 40000 ./fasttext/teaser.preprocessed.txt > ./fasttext/teaser_cl.train\n",
    "!tail -n 15000 ./fasttext/teaser.preprocessed.txt > ./fasttext/teaser_cl.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  51697\n",
      "Number of labels: 21\n",
      "Progress: 100.0% words/sec/thread: 1067246 lr:  0.000000 avg.loss:  0.376231 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14794, 0.5892929566040287, 0.5892929566040287)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier with cleaned teaser tested on teaser\n",
    "train_file=\"./fasttext/teaser_cl.train\"\n",
    "model_file=\"./fasttext/model_teaser_cl_output.bin\"\n",
    "test_file=\"./fasttext/teaser_cl.valid\"\n",
    "\n",
    "model_teaser_cl = fasttext.train_supervised(input=train_file, lr=0.9, epoch=25)\n",
    "#saving the model\n",
    "model_teaser_cl.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_cl.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  66706\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread: 1065250 lr:  0.000000 avg.loss:  0.680163 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68481, 0.6716899577985135, 0.6716899577985135)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, epoch=12)\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, epoch=50, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  66706\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  582548 lr:  0.000000 avg.loss:  5.385403 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68481, 0.625472758867423, 0.625472758867423)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, wordNgrams=5, epoch=50, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google keywords to dw categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skipgram model :\n",
    "# model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
    "\n",
    "# # or, cbow model :\n",
    "# model = fasttext.train_unsupervised('data.txt', model='cbow')\n",
    "\n",
    "\n",
    "# print(model.words)   # list of words in dictionary\n",
    "# print(model['king']) # get the vector of the word 'king'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
