{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext\n",
    "\n",
    "following tutorial https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- prepare an input file with categories and their keywords\n",
    "- prepare input file with categories and single keywords\n",
    "- split datasets in training and validation\n",
    "- run simple model settings (default as above)\n",
    "- balance datasets for training \n",
    " - feed GOOOGLE search words!\n",
    "\n",
    " \n",
    "- try to use it as a word vectorizer and measure distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "Loading data DONE. Number of articles is 175659\n",
      "Extracting data DONE. Number of articles from 2017-01-01 to 2022-01-01 is 69432\n"
     ]
    }
   ],
   "source": [
    "## load the data\n",
    "import sys\n",
    "# Add src folder to the path\n",
    "sys.path.append('../src/')\n",
    "from data.preprocess_keywords import make_cleaned_keywords_df\n",
    "from data.make_datasets import get_data\n",
    "# Specify wanted time range\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2022-01-01'\n",
    "# Path to data\n",
    "data_file = '/home/anya_m/data/dw-project-data/CMS_2010_to_June_2022_ENGLISH.json'\n",
    "# Load and extract data within time range\n",
    "df_subset = get_data(data_file, start_date, end_date)\n",
    "# Cleans keywords and saves data as a dataframe\n",
    "#make_cleaned_keywords_df(df_subset, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DW data\n",
    "import pandas as pd\n",
    "start_date = '2017-01-01' #'2019-01-01' #'2021-01-01'\n",
    "end_date = '2022-01-01'\n",
    "filepath = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "df = pd.read_json(filepath, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "69432"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(len(df))\n",
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Google data\n",
    "df_google = pd.read_json('../data/interim/2021-daily-trending-searches.json', orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only google data within DW data date range\n",
    "start_date_dw=start_date\n",
    "end_date_dw=end_date\n",
    "df_google.sort_values(by ='date', inplace = True) \n",
    "mask = (pd.to_datetime(df_google['date']) > start_date_dw) & (pd.to_datetime(df_google['date']) <= end_date_dw)\n",
    "df_google_subset = df_google.loc[mask].copy()\n",
    "google_topic=df_google_subset['topic_title']\n",
    "google_topic_type=df_google_subset['topic_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>formattedValue</th>\n",
       "      <th>link</th>\n",
       "      <th>topic_mid</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3900</td>\n",
       "      <td>+3,900%</td>\n",
       "      <td>/trends/explore?q=/m/01wf86y&amp;date=2021-01-01+2...</td>\n",
       "      <td>/m/01wf86y</td>\n",
       "      <td>Cyndi Lauper</td>\n",
       "      <td>American singer</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>+60%</td>\n",
       "      <td>/trends/explore?q=/m/02vx4&amp;date=2021-01-01+202...</td>\n",
       "      <td>/m/02vx4</td>\n",
       "      <td>Football</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>+60%</td>\n",
       "      <td>/trends/explore?q=/m/0frq6&amp;date=2021-01-01+202...</td>\n",
       "      <td>/m/0frq6</td>\n",
       "      <td>Pork</td>\n",
       "      <td>Meat</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>+60%</td>\n",
       "      <td>/trends/explore?q=/m/0735l&amp;date=2021-01-01+202...</td>\n",
       "      <td>/m/0735l</td>\n",
       "      <td>Streaming media</td>\n",
       "      <td>Topic</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>70</td>\n",
       "      <td>+70%</td>\n",
       "      <td>/trends/explore?q=/m/07gyp7&amp;date=2021-01-01+20...</td>\n",
       "      <td>/m/07gyp7</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Fast food chain</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    value formattedValue                                               link  \\\n",
       "0    3900        +3,900%  /trends/explore?q=/m/01wf86y&date=2021-01-01+2...   \n",
       "24     60           +60%  /trends/explore?q=/m/02vx4&date=2021-01-01+202...   \n",
       "23     60           +60%  /trends/explore?q=/m/0frq6&date=2021-01-01+202...   \n",
       "22     60           +60%  /trends/explore?q=/m/0735l&date=2021-01-01+202...   \n",
       "21     70           +70%  /trends/explore?q=/m/07gyp7&date=2021-01-01+20...   \n",
       "\n",
       "     topic_mid      topic_title       topic_type       date location  \n",
       "0   /m/01wf86y     Cyndi Lauper  American singer 2021-01-01       US  \n",
       "24    /m/02vx4         Football           Sports 2021-01-01       US  \n",
       "23    /m/0frq6             Pork             Meat 2021-01-01       US  \n",
       "22    /m/0735l  Streaming media            Topic 2021-01-01       US  \n",
       "21   /m/07gyp7       McDonald's  Fast food chain 2021-01-01       US  "
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_google_subset.head()\n",
    "#interesting columns:\n",
    "# df_google_subset['topic_title']\n",
    "# df_google_subset['topic_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column teaser to the df cleaned dataframe\n",
    "df=df.merge(df_subset['teaser'], left_on=df_subset['id'], right_on=df['id'])\n",
    "df=df.drop(['key_0'], axis=1)\n",
    "df=df.drop(['keywordStrings'], axis=1)\n",
    "#add column with full text of the article into the dataframe\n",
    "# df=df.merge(df_subset['text'], left_on=df['id'], right_on=df_subset['id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == \"\":\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/anya_m/Documents/git_dw/venv/lib64/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#remove all NaN fields\n",
    "df_clean=df.dropna(how='any')\n",
    "df_clean_copy = df_clean.copy(deep=True)\n",
    "##TODO\n",
    "#df_clean['cleanFocusCategory']=='Law and Justice' replace with Law-and-Justice  and other categories\n",
    "\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Law and Justice'], 'Law-and-Justice')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Nature and Environment'], 'Nature-and-Environment')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Human Rights'], 'Human-Rights')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Cars and Transportation'], 'Cars-and-Transportation')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Press Freedom'], 'Press-Freedom')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Digital World'], 'Digital-World')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Rule of Law'], 'Rule-of-Law')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Learning German'], 'Learning-German')\n",
    "df_clean['cleanFocusCategory'] = df_clean['cleanFocusCategory'].replace(['Freedom of Speech'], 'Freedom-of-Speech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['History', 'Politics', 'Society', 'Culture', 'Media',\n",
       "       'Law-and-Justice', 'Catastrophe', 'Lifestyle', 'Business',\n",
       "       'Travel', 'Sports', 'Science', 'Health', 'Nature-and-Environment',\n",
       "       'Cars-and-Transportation', 'Education', 'Religion', 'Human-Rights',\n",
       "       'Technology', 'Learning-German', 'Digital-World', 'Migration',\n",
       "       'Offbeat', 'Innovation'], dtype=object)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['cleanFocusCategory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_single_kw=df_clean.explode('keywordStringsCleanAfterFuzz')\n",
    "\n",
    "label=df_clean['cleanFocusCategory'].apply(lambda x: ('__label__' +x+' '))\n",
    "kw=df_clean['keywordStringsCleanAfterFuzz'].apply(lambda x: (', '.join(x)))\n",
    "teaser=df_clean['teaser']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_single_kw=df_clean_single_kw.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_kw_label=df_clean_single_kw['cleanFocusCategory'].apply(lambda x: ('__label__' +x+' '))\n",
    "single_kw=df_clean_single_kw['keywordStringsCleanAfterFuzz']\n",
    "print(single_kw_label+single_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label+teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        __label__History Margaret Thatcher, Helmut Koh...\n",
      "1        __label__Politics Syria, Russia, rebels, cease...\n",
      "2        __label__Politics Syria, Yemen, war, Bashar al...\n",
      "3        __label__Politics Syria, Russia, Donald Trump,...\n",
      "4                          __label__Politics Angela Merkel\n",
      "                               ...                        \n",
      "69427    __label__Politics Putin, New Year, Coronavirus...\n",
      "69428    __label__Politics Germany, Olaf Scholz, New Ye...\n",
      "69429    __label__Catastrophe Colorado, wildfires, Boul...\n",
      "69430    __label__Business RCEP, Regional Comprehensive...\n",
      "69431    __label__Health France, birth control, contrac...\n",
      "Length: 68481, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(label+kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_kw=label+kw\n",
    "label_single_kw=single_kw_label+single_kw\n",
    "label_teaser=label+teaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test subsets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "def split_dataset(dataset, label):\n",
    "    train_set, test_set=tts(dataset, random_state=0, test_size=0.33, stratify=label)\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_kw_train,label_kw_test=split_dataset(label_kw,label)\n",
    "label_single_kw_train,label_single_kw_test=split_dataset(label_single_kw,single_kw_label)\n",
    "label_teaser_train,label_teaser_test=split_dataset(label_teaser,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘./fasttext/single_kw.txt’: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "358724it [00:06, 52690.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# save training/validation file for fasttext\n",
    "#label+single keyword (all keywords using pd.explode)\n",
    "from tqdm import tqdm\n",
    "!rm ./fasttext/single_kw.txt\n",
    "with open('./fasttext/single_kw.txt', 'a') as f:\n",
    "    for i, el in tqdm(enumerate(single_kw_label)):\n",
    "        #print(i)\n",
    "        #print(kw[i])\n",
    "        print(el+single_kw.iloc[i],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68481it [00:01, 49098.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# save training/validation file for fasttext\n",
    "#label+teaser\n",
    "from tqdm import tqdm\n",
    "!rm ./fasttext/teaser.txt\n",
    "with open('./fasttext/teaser.txt', 'a') as f:\n",
    "    for i, el in tqdm(enumerate(label)):\n",
    "        #print(i)\n",
    "        #print(kw[i])\n",
    "        print(el+teaser.iloc[i],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68481it [00:01, 55123.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# save training/validation file for fasttext\n",
    "#label+all DW keywords\n",
    "from tqdm import tqdm\n",
    "!rm ./fasttext/output.txt\n",
    "with open('./fasttext/output.txt', 'a') as f:\n",
    "    for i, el in tqdm(enumerate(label)):\n",
    "        #print(i)\n",
    "        #print(kw[i])\n",
    "        print(el+kw.iloc[i],file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_txt(out_name,data_to_save):\n",
    "    from tqdm import tqdm\n",
    "    #!rm $out_name\n",
    "    if os.path.isfile(out_name):\n",
    "        os.remove(out_name)\n",
    "    with open(out_name,'a') as f:\n",
    "        for i,el in tqdm(enumerate(data_to_save)):\n",
    "            print(el,file=f)\n",
    "    input_file=out_name\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45882it [00:00, 385445.01it/s]\n",
      "22599it [00:00, 350453.20it/s]\n"
     ]
    }
   ],
   "source": [
    "all_kw_train=save_txt('./fasttext/all_kw_train.txt',label_kw_train)\n",
    "all_kw_test=save_txt('./fasttext/all_kw_test.txt',label_kw_test)\n",
    "#all_kw_train\n",
    "#!head ./fasttext/all_kw_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240345it [00:00, 282301.57it/s]\n",
      "118379it [00:00, 262190.10it/s]\n"
     ]
    }
   ],
   "source": [
    "single_kw_train=save_txt('./fasttext/single_kw_train.txt',label_single_kw_train)\n",
    "single_kw_test=save_txt('./fasttext/single_kw_test.txt',label_single_kw_test)\n",
    "\n",
    "!cat ./fasttext/single_kw_train.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/single_kw_train.preprocessed.txt\n",
    "!cat ./fasttext/single_kw_test.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/single_kw_test.preprocessed.txt\n",
    "\n",
    "single_kw_train_prec='./fasttext/single_kw_train.preprocessed.txt'\n",
    "single_kw_test_prec='./fasttext/single_kw_test.preprocessed.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45882it [00:00, 121746.47it/s]\n",
      "22599it [00:00, 118641.79it/s]\n"
     ]
    }
   ],
   "source": [
    "teaser_train=save_txt('./fasttext/teaser_train.txt',label_teaser_train)\n",
    "teaser_test=save_txt('./fasttext/teaser_test.txt',label_teaser_test)\n",
    "\n",
    "!cat ./fasttext/teaser_train.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/teaser_train.preprocessed.txt\n",
    "!cat ./fasttext/teaser_test.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/teaser_test.preprocessed.txt\n",
    "\n",
    "teaser_train_prec='./fasttext/teaser_train.preprocessed.txt'\n",
    "teaser_test_prec='./fasttext/teaser_test.preprocessed.txt'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Fasttext\n",
    "- DW all kw + DW cats  - training + validation\n",
    "- DW all kw for training, DW single kw for validation\n",
    "- DW single kw for training + validation\n",
    "- DW teaser + DW cats          - training + validation\n",
    "\n",
    "implement train_test_split for splitting dataset\n",
    "\n",
    "- DW teaser / kw for training , google for ???\n",
    "- - validation based on similarity of google to DW kw (rapidfuzz? cdist / word embeddings using fasstext)\n",
    "\n",
    "- - make graphics to compare categories from DW and Google\n",
    "\n",
    "- DW text for training, DW kw for validation\n",
    "- - clean html (beautiful soup?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing dataset into training and validation sets\n",
    "\n",
    "!head -n 50000 ./fasttext/output.txt > ./fasttext/output.train\n",
    "!tail -n 20000 ./fasttext/output.txt > ./fasttext/output.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing dataset into training and validation sets\n",
    "!cat ./fasttext/output.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/output.preprocessed.txt\n",
    "\n",
    "!head -n 50000 ./fasttext/output.preprocessed.txt > ./fasttext/output_cl.train\n",
    "!tail -n 20000 ./fasttext/output.preprocessed.txt > ./fasttext/output_cl.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single kw \n",
    "#preprocessing and \n",
    "#splittig into training and validation sets\n",
    "!cat ./fasttext/single_kw.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > ./fasttext/single_kw.preprocessed.txt\n",
    "\n",
    "!head -n 300000 ./fasttext/single_kw.preprocessed.txt > ./fasttext/single_kw_cl.train\n",
    "!tail -n 60000 ./fasttext/single_kw.preprocessed.txt > ./fasttext/single_kw_cl.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_classifier(train_file,test_file,lr=1.0,epoch=12,k=1,wordNgrams=1):\n",
    "    model = fasttext.train_supervised(input=train_file, lr=lr, epoch=epoch)\n",
    "    #model.test(test_file,k=k)\n",
    "    print(model.test(test_file,k=1))\n",
    "    print(model.test(test_file,k=2))\n",
    "    print(model.test(test_file,k=3))\n",
    "    print(model.test(test_file,k=4))\n",
    "    print(model.test(test_file,k=5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  36772\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  448071 lr:  0.000000 avg.loss:  0.536056 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22599, 0.6917120226558697, 0.6917120226558697)\n",
      "(22599, 0.41285012611177485, 0.8257002522235497)\n",
      "(22599, 0.29516055282682124, 0.8854816584804638)\n",
      "(22599, 0.22923580689411036, 0.9169432275764414)\n",
      "(22599, 0.18739767246338335, 0.9369883623169166)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22599, 0.6917120226558697, 0.6917120226558697)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_kw_check=fasttext_classifier(all_kw_train,all_kw_test,lr=0.7)\n",
    "#model_all_kw_check.test(all_kw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  28776\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  195677 lr:  0.000000 avg.loss: 10.151832 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118379, 0.5124050718455131, 0.5124050718455131)\n",
      "(118379, 0.25624054942177243, 0.5124810988435449)\n",
      "(118379, 0.17112832512523335, 0.5133849753757)\n",
      "(118379, 0.1311360122994788, 0.5245440491979152)\n",
      "(118379, 0.12260451600368309, 0.6130225800184155)\n"
     ]
    }
   ],
   "source": [
    "model_single_kw_check=fasttext_classifier(single_kw_train,single_kw_test,lr=0.7,wordNgrams=1)\n",
    "#model_single_kw_check.test(single_kw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  28776\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  244412 lr:  0.000000 avg.loss: 10.170701 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118379, 0.5066354674393262, 0.5066354674393262)\n",
      "(118379, 0.2533515234965661, 0.5067030469931322)\n",
      "(118379, 0.16922765017443972, 0.5076829505233191)\n",
      "(118379, 0.12984144147188267, 0.5193657658875307)\n",
      "(118379, 0.12065315638753495, 0.6032657819376748)\n"
     ]
    }
   ],
   "source": [
    "model_single_kw_check=fasttext_classifier(single_kw_train,single_kw_test,lr=0.7,wordNgrams=5)\n",
    "#model_single_kw_check.test(single_kw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  28595\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  223871 lr:  0.000000 avg.loss: 10.209421 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118379, 0.5109183216617812, 0.5109183216617812)\n",
      "(118379, 0.25548872688568075, 0.5109774537713615)\n",
      "(118379, 0.17073411106136505, 0.5122023331840951)\n",
      "(118379, 0.13140844237575922, 0.5256337695030369)\n",
      "(118379, 0.12208584292822207, 0.6104292146411103)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(118379, 0.5109183216617812, 0.5109183216617812)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_single_kw_check_prec=fasttext_classifier(single_kw_train_prec,single_kw_test_prec,lr=0.7)\n",
    "#model_single_kw_check_prec.test(single_kw_test_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  89320\n",
      "Number of labels: 24\n",
      "Progress:  98.9% words/sec/thread:  820660 lr:  0.011198 avg.loss:  0.601301 ETA:   0h 0m 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22599, 0.6690119031815567, 0.6690119031815567)\n",
      "(22599, 0.40249568564980753, 0.8049913712996151)\n",
      "(22599, 0.2884198415859109, 0.8652595247577326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% words/sec/thread:  819037 lr:  0.000000 avg.loss:  0.594989 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22599, 0.22408071153590867, 0.8963228461436347)\n",
      "(22599, 0.18339749546440107, 0.9169874773220054)\n"
     ]
    }
   ],
   "source": [
    "model_teaser=fasttext_classifier(teaser_train,teaser_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  54981\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  794113 lr:  0.000000 avg.loss:  0.772094 ETA:   0h 0m 0s100.0% words/sec/thread:  794117 lr: -0.000005 avg.loss:  0.772094 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22599, 0.6777291030576574, 0.6777291030576574)\n",
      "(22599, 0.4076286561352272, 0.8152573122704544)\n",
      "(22599, 0.29272681682080326, 0.8781804504624099)\n",
      "(22599, 0.22819593787335724, 0.9127837514934289)\n",
      "(22599, 0.18667197663613433, 0.9333598831806718)\n"
     ]
    }
   ],
   "source": [
    "model_teaser=fasttext_classifier(teaser_train_prec,teaser_test_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  54981\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  999731 lr:  0.000000 avg.loss:  0.819998 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118379, 0.3832774394107063, 0.3832774394107063)\n",
      "(118379, 0.26068812880662956, 0.5213762576132591)\n",
      "(118379, 0.20177565277625253, 0.6053269583287576)\n",
      "(118379, 0.16474416915162318, 0.6589766766064927)\n",
      "(118379, 0.13969876413890978, 0.6984938206945489)\n"
     ]
    }
   ],
   "source": [
    "model_teaser_single=fasttext_classifier(teaser_train_prec,single_kw_test_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   13 Best score:  0.526998 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 0M words\n",
      "Number of words:  34650\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  535450 lr:  0.000000 avg.loss:  1.001028 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(358724, 0.522613485576655, 0.522613485576655)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best_all_single = fasttext.train_supervised(input=\"./fasttext/output.preprocessed.txt\", autotuneValidationFile=\"./fasttext/single_kw.preprocessed.txt\")\n",
    "model_best_all_single.test(\"./fasttext/single_kw.preprocessed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   10 Best score:  0.527900 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 1M words\n",
      "Number of words:  31928\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  227185 lr:  0.000000 avg.loss:  1.242923 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 0.518, 0.518)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#automatic search for best hyperparameters https://fasttext.cc/docs/en/autotune.html \n",
    "#last 5 minutes\n",
    "train_file=\"./fasttext/single_kw_cl.train\"\n",
    "valid_file='./fasttext/single_kw_cl.valid'\n",
    "model_best_single = fasttext.train_supervised(input=train_file, autotuneValidationFile=valid_file)\n",
    "model_best_single.test(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   23 Best score:  0.658736 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 0M words\n",
      "Number of words:  31769\n",
      "Number of labels: 22\n",
      "Progress: 100.0% words/sec/thread:  741156 lr:  0.000000 avg.loss:  0.837053 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "#automatic search for best hyperparameters https://fasttext.cc/docs/en/autotune.html \n",
    "#last 5 minutes\n",
    "model_best = fasttext.train_supervised(input=train_file, autotuneValidationFile='./fasttext/output_cl.valid')\n",
    "model_best.test('./fasttext/output_cl.valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output are the number of samples (here 14999), \n",
    "# the precision at one (0.6968)  69% and \n",
    "# the recall at one (0.0541).\n",
    "\n",
    "#The precision is the number of correct labels among the labels predicted by fastText. \n",
    "# The recall is the number of labels that successfully were predicted,\n",
    "# among all the real labels. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a few steps, we were able to go from a precision at one of 12.4% to 59.9%. Important steps included:\n",
    "\n",
    "- preprocessing the data ;\n",
    "- changing the number of epochs (using the option -epoch, standard range [5 - 50]) ;\n",
    "- changing the learning rate (using the option -lr, standard range [0.1 - 1.0]) ;\n",
    "- using word n-grams (using the option -wordNgrams, standard range [1 - 5])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  51697\n",
      "Number of labels: 21\n",
      "Progress: 100.0% words/sec/thread: 1067246 lr:  0.000000 avg.loss:  0.376231 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14794, 0.5892929566040287, 0.5892929566040287)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier with cleaned teaser tested on teaser\n",
    "train_file=\"./fasttext/teaser_cl.train\"\n",
    "model_file=\"./fasttext/model_teaser_cl_output.bin\"\n",
    "test_file=\"./fasttext/teaser_cl.valid\"\n",
    "\n",
    "model_teaser_cl = fasttext.train_supervised(input=train_file, lr=0.9, epoch=25)\n",
    "#saving the model\n",
    "model_teaser_cl.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_cl.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  66706\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread: 1065250 lr:  0.000000 avg.loss:  0.680163 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68481, 0.6716899577985135, 0.6716899577985135)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, epoch=12)\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, epoch=50, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  66706\n",
      "Number of labels: 24\n",
      "Progress: 100.0% words/sec/thread:  582548 lr:  0.000000 avg.loss:  5.385403 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68481, 0.625472758867423, 0.625472758867423)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier with cleaned teaser tested on DW kw\n",
    "train_file=\"./fasttext/teaser.preprocessed.txt\" #all cleaned teasers +cat\n",
    "model_file=\"./fasttext/model_teaser_pred_kw.bin\"\n",
    "test_file=\"./fasttext/output.preprocessed.txt\" #all cleaned dw kw + cat\n",
    "\n",
    "model_teaser_kw = fasttext.train_supervised(input=train_file, lr=1.0, wordNgrams=5, epoch=50, bucket=200000, dim=50, loss='hs')\n",
    "#saving the model\n",
    "model_teaser_kw.save_model(model_file)\n",
    "#test model\n",
    "\n",
    "model_teaser_kw.test(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google keywords to dw categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Skipgram model :\n",
    "# model = fasttext.train_unsupervised('data.txt', model='skipgram')\n",
    "\n",
    "# # or, cbow model :\n",
    "# model = fasttext.train_unsupervised('data.txt', model='cbow')\n",
    "\n",
    "\n",
    "# print(model.words)   # list of words in dictionary\n",
    "# print(model['king']) # get the vector of the word 'king'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
