{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# Opening JSON file\n",
    "f = open('/home/ferdinand_t/data/CMS_2010_to_June_2022_ENGLISH.json')\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['firstKeyword'] = df['keywords'].apply(lambda x: x[0]['name'] if len(x) != 0 else None)\n",
    "# #df['secondKeyword'] = df['keywords'].apply(lambda x: x[1]['name'] if len(x) > 1 else None)\n",
    "# #df['thirdKeyword'] = df['keywords'].apply(lambda x: x[2]['name'] if len(x) > 2 else None)\n",
    "# #df['fourthKeyword'] = df['keywords'].apply(lambda x: x[3]['name'] if len(x) > 3 else None)\n",
    "\n",
    "df['cleanFocusCategory'] = df['thematicFocusCategory'].apply(lambda x: x['name'] if x is not None else x)\n",
    "\n",
    "# #df = df[['firstKeyword', 'secondKeyword', 'thirdKeyword', 'fourthKeyword', 'thematicFocusCategory', 'cleanFocusCategory']]\n",
    "\n",
    "df = df[['firstKeyword', 'keywordStrings', 'cleanFocusCategory']]\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.dropna()\n",
    "# df_clean['cleanKeywordStrings'] = [' '.join(map(str, l)) for l in df_clean['keywordStrings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"/home/ferdinand_t/Downloads/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79913, 38705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>08</th>\n",
       "      <th>0rg</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>øystein</th>\n",
       "      <th>út</th>\n",
       "      <th>überall</th>\n",
       "      <th>ünal</th>\n",
       "      <th>ünker</th>\n",
       "      <th>ľudmila</th>\n",
       "      <th>şehriban</th>\n",
       "      <th>štefániková</th>\n",
       "      <th>żurek</th>\n",
       "      <th>cleanFocusCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Conflicts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  007  01  03  04  05  08  0rg  10  100  ...  øystein  út  überall  \\\n",
       "0    0    0   0   0   0   0   0    0   0    0  ...        0   0        0   \n",
       "1    0    0   0   0   0   0   0    0   0    0  ...        0   0        0   \n",
       "2    0    0   0   0   0   0   0    0   0    0  ...        0   0        0   \n",
       "3    0    0   0   0   0   0   0    0   0    0  ...        0   0        0   \n",
       "4    0    0   0   0   0   0   0    0   0    0  ...        0   0        0   \n",
       "\n",
       "   ünal  ünker  ľudmila  şehriban  štefániková  żurek  cleanFocusCategory  \n",
       "0     0      0        0         0            0      0             History  \n",
       "1     0      0        0         0            0      0            Business  \n",
       "2     0      0        0         0            0      0            Business  \n",
       "3     0      0        0         0            0      0           Conflicts  \n",
       "4     0      0        0         0            0      0            Politics  \n",
       "\n",
       "[5 rows x 38705 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#corpus_train, corpus_test, label_train, label_test, indices_train, indices_test = train_test_split(df_clean['keywordStrings'], df_clean['cleanFocusCategory'].astype(str), df_clean.index, test_size=0.33, random_state=0) \n",
    "# Ticket Data\n",
    "corpus = df_clean['keywordStrings'].astype(str)\n",
    " \n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1),stop_words='english')\n",
    " \n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "#print(vectorizer.get_feature_names())\n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "CountVectorizedData['cleanFocusCategory']=df_clean['cleanFocusCategory'].values\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsVocab=CountVectorizedData.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<79913x38704 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 592156 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'commerzbank' in WordsVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def FunctionText2Vec(inpTextData):\n",
    "#     # Converting the text to numeric data\n",
    "#     X = vectorizer.transform(inpTextData)\n",
    "#     CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "#     # Creating empty dataframe to hold sentences\n",
    "#     W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "#     # Looping through each row for the data\n",
    "#     for i in range(CountVecData.shape[0]):\n",
    " \n",
    "#         # initiating a sentence with all zeros\n",
    "#         Sentence = np.zeros(300)\n",
    " \n",
    "#         # Looping thru each word in the sentence and if its present in \n",
    "#         # the Word2Vec model then storing its vector\n",
    "#         for word in WordsVocab[CountVecData.iloc[i , :]>=1]:\n",
    "#             #print(word)\n",
    "#             if word in wv.key_to_index.keys():    \n",
    "#                 Sentence=Sentence+wv[word]\n",
    "#         # Appending the sentence to the dataframe\n",
    "#         W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence]))\n",
    "#     return(W2Vec_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#W2Vec_Data=FunctionText2Vec(df_clean['keywordStrings'][0:20].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# X = vectorizer.transform(df_clean['keywordStrings'][0:2].astype(str))\n",
    "# CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "#     # Creating empty dataframe to hold sentences\n",
    "# W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "#     # Looping through each row for the data\n",
    "# for i in range(CountVecData.shape[0]):\n",
    " \n",
    "#         # initiating a sentence with all zeros\n",
    "#     Sentence = np.zeros(300)\n",
    " \n",
    "#         # Looping thru each word in the sentence and if its present in \n",
    "#         # the Word2Vec model then storing its vector\n",
    "#     for word in WordsVocab[CountVecData.iloc[i , :]>=1]:\n",
    "#             #print(word)\n",
    "#         if word in wv.key_to_index.keys():    \n",
    "#             Sentence=Sentence+wv[word]\n",
    "#         elif word.capitalize() in wv.key_to_index.keys():\n",
    "#             Sentence=Sentence+wv[word.capitalize()]\n",
    "#         else: \n",
    "#             print(word)\n",
    "#         # Appending the sentence to the dataframe\n",
    "#     W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVecData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W2Vec_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_clean.loc['8762','keywordStrings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_clean.loc['31542','keywordStrings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = vectorizer.transform(df_clean['keywordStrings'].astype(str))\n",
    "CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "W2Vec_Data_temp=pd.DataFrame()\n",
    "    \n",
    "Sentence_1=[[wv[word] if word in wv.key_to_index.keys() else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_1))\n",
    "Sentence_2=[[wv[word.capitalize()] if word.capitalize() in wv.key_to_index.keys() and word not in wv.key_to_index.keys()  else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_2))\n",
    "test_sum_df = W2Vec_Data_temp.groupby(W2Vec_Data_temp.index).sum()\n",
    "#W2Vec_Data = test_sum_df.sum(axis=1)\n",
    "test_sum_df[test_sum_df.applymap(lambda x: np.allclose(x, 0))] = np.nan\n",
    "W2Vec_Data = test_sum_df.apply(lambda x: np.mean(x[x.notnull()]), axis=1)\n",
    "W2Vec_Data_df = pd.DataFrame(W2Vec_Data)\n",
    "W2Vec_Data_df_final = W2Vec_Data_df[0].apply(pd.Series)\n",
    "W2Vec_Data = W2Vec_Data_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['africa', 'africalink', 'crossroads', 'difference', 'generation',\n",
       "       'headlines', 'making', 'say', 'story'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordsVocab[CountVecData.iloc[0 , :]>=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000            False\n",
       "007            False\n",
       "01             False\n",
       "03             False\n",
       "04             False\n",
       "               ...  \n",
       "ünker          False\n",
       "ľudmila        False\n",
       "şehriban       False\n",
       "štefániková    False\n",
       "żurek          False\n",
       "Name: 0, Length: 38704, dtype: bool"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVecData.iloc[0 , :]>=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>cleanFocusCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037458</td>\n",
       "      <td>0.035431</td>\n",
       "      <td>-0.015442</td>\n",
       "      <td>0.043671</td>\n",
       "      <td>-0.070129</td>\n",
       "      <td>-0.047699</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>-0.150574</td>\n",
       "      <td>0.131897</td>\n",
       "      <td>0.155594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>-0.087601</td>\n",
       "      <td>-0.044266</td>\n",
       "      <td>-0.109833</td>\n",
       "      <td>-0.113205</td>\n",
       "      <td>-0.017700</td>\n",
       "      <td>-0.060272</td>\n",
       "      <td>0.050583</td>\n",
       "      <td>0.054138</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064799</td>\n",
       "      <td>0.054057</td>\n",
       "      <td>-0.156643</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>-0.097010</td>\n",
       "      <td>-0.103119</td>\n",
       "      <td>-0.005575</td>\n",
       "      <td>-0.073738</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.069987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018105</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.034078</td>\n",
       "      <td>0.159627</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.086344</td>\n",
       "      <td>-0.116781</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018377</td>\n",
       "      <td>-0.021179</td>\n",
       "      <td>-0.033508</td>\n",
       "      <td>0.115753</td>\n",
       "      <td>-0.068568</td>\n",
       "      <td>0.014430</td>\n",
       "      <td>0.032796</td>\n",
       "      <td>-0.126007</td>\n",
       "      <td>0.115804</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194115</td>\n",
       "      <td>-0.118530</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>-0.031565</td>\n",
       "      <td>0.010111</td>\n",
       "      <td>0.117445</td>\n",
       "      <td>0.077148</td>\n",
       "      <td>-0.022380</td>\n",
       "      <td>0.059703</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102661</td>\n",
       "      <td>0.137807</td>\n",
       "      <td>0.086599</td>\n",
       "      <td>0.012533</td>\n",
       "      <td>-0.016418</td>\n",
       "      <td>-0.016357</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>-0.199870</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.196411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083537</td>\n",
       "      <td>-0.106913</td>\n",
       "      <td>0.098002</td>\n",
       "      <td>-0.084615</td>\n",
       "      <td>0.054179</td>\n",
       "      <td>-0.143148</td>\n",
       "      <td>-0.037420</td>\n",
       "      <td>0.104960</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>Conflicts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043797</td>\n",
       "      <td>-0.020020</td>\n",
       "      <td>0.067062</td>\n",
       "      <td>0.121277</td>\n",
       "      <td>-0.124695</td>\n",
       "      <td>0.159302</td>\n",
       "      <td>0.042175</td>\n",
       "      <td>-0.220093</td>\n",
       "      <td>0.106903</td>\n",
       "      <td>0.036682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047852</td>\n",
       "      <td>-0.077698</td>\n",
       "      <td>-0.012573</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>-0.174744</td>\n",
       "      <td>-0.094299</td>\n",
       "      <td>-0.274170</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>-0.083557</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.037458  0.035431 -0.015442  0.043671 -0.070129 -0.047699  0.074829   \n",
       "1  0.064799  0.054057 -0.156643  0.065023 -0.097010 -0.103119 -0.005575   \n",
       "2  0.018377 -0.021179 -0.033508  0.115753 -0.068568  0.014430  0.032796   \n",
       "3  0.102661  0.137807  0.086599  0.012533 -0.016418 -0.016357  0.057058   \n",
       "4  0.043797 -0.020020  0.067062  0.121277 -0.124695  0.159302  0.042175   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0 -0.150574  0.131897  0.155594  ...  0.000526 -0.087601 -0.044266 -0.109833   \n",
       "1 -0.073738  0.069585  0.069987  ... -0.018105  0.012492  0.032450  0.034078   \n",
       "2 -0.126007  0.115804  0.035848  ...  0.194115 -0.118530  0.013265 -0.031565   \n",
       "3 -0.199870  0.013702  0.196411  ... -0.083537 -0.106913  0.098002 -0.084615   \n",
       "4 -0.220093  0.106903  0.036682  ... -0.047852 -0.077698 -0.012573  0.050293   \n",
       "\n",
       "        295       296       297       298       299  cleanFocusCategory  \n",
       "0 -0.113205 -0.017700 -0.060272  0.050583  0.054138             History  \n",
       "1  0.159627  0.022573  0.039103  0.086344 -0.116781            Business  \n",
       "2  0.010111  0.117445  0.077148 -0.022380  0.059703            Business  \n",
       "3  0.054179 -0.143148 -0.037420  0.104960  0.117086           Conflicts  \n",
       "4 -0.174744 -0.094299 -0.274170  0.049637 -0.083557            Politics  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO THEN I DONT HAVE TO CREATE THE DATAFRAME BEFORE THAT STEP\n",
    "# Adding the target variable\n",
    "W2Vec_Data.reset_index(inplace=True, drop=True)\n",
    "W2Vec_Data['cleanFocusCategory']=CountVectorizedData['cleanFocusCategory']\n",
    " \n",
    "# Assigning to DataForML variable\n",
    "DataForML=W2Vec_Data\n",
    "DataForML.loc[DataForML.isna().any(axis=1),0:299] = 0\n",
    "DataForML.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=DataForML.columns[-1]\n",
    "Predictors=DataForML.columns[:-1]\n",
    " \n",
    "X=DataForML[Predictors].values\n",
    "y=DataForML[TargetVariable].values\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# X = vectorizer.transform(df_clean['firstKeyword'].astype(str))\n",
    "# CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "#     # Creating empty dataframe to hold sentences\n",
    "# W2Vec_Data_temp=pd.DataFrame()\n",
    "    \n",
    "# Sentence_1=[[wv[word] if word in wv.key_to_index.keys() else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "# W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_1))        \n",
    "# Sentence_2=[[wv[word.capitalize()] if word.capitalize() in wv.key_to_index.keys() and word not in wv.key_to_index.keys()  else np.zeros(300) for word in WordsVocab[CountVecData.iloc[i , :]>=1]] for i in range(CountVecData.shape[0])]\n",
    "# W2Vec_Data_temp=W2Vec_Data_temp.append(pd.DataFrame(Sentence_2))\n",
    "# test_sum_df = W2Vec_Data_temp.groupby(W2Vec_Data_temp.index).sum()\n",
    "# #W2Vec_Data = test_sum_df.sum(axis=1)\n",
    "# test_sum_df[test_sum_df.applymap(lambda x: np.allclose(x, 0))] = np.nan\n",
    "# W2Vec_Data = test_sum_df.apply(lambda x: np.mean(x[x.notnull()]), axis=1)\n",
    "# W2Vec_Data_df = pd.DataFrame(W2Vec_Data)\n",
    "# W2Vec_Data_df_final = W2Vec_Data_df[0].apply(pd.Series)\n",
    "# W2Vec_Data = W2Vec_Data_df_final\n",
    "# W2Vec_Data.reset_index(inplace=True, drop=True)\n",
    "# W2Vec_Data['cleanFocusCategory']=CountVectorizedData['cleanFocusCategory']\n",
    "# # Assigning to DataForML variable\n",
    "# DataForML_fkw=W2Vec_Data\n",
    "# DataForML_fkw.loc[DataForML_fkw.isna().any(axis=1),0:299] = 0\n",
    "\n",
    "# # Separate Target Variable and Predictor Variables\n",
    "# TargetVariable_fkw=DataForML_fkw.columns[-1]\n",
    "# Predictors_fkw=DataForML_fkw.columns[:-1]\n",
    " \n",
    "# X_fkw=DataForML_fkw[Predictors_fkw].values\n",
    "# y_fkw=DataForML_fkw[TargetVariable_fkw].values\n",
    "\n",
    "# X_train_fkw, X_test_fkw, y_train_fkw, y_test_fkw = train_test_split(X_fkw, y_fkw, test_size=0.25, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59934, 300)\n",
      "(59934,)\n",
      "(19979, 300)\n",
      "(19979,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sanity check for the sampled data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6488312728364783"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "PredictorScaler=StandardScaler()\n",
    " \n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    " \n",
    "# Generating the standardized values of X\n",
    "X=PredictorScalerFit.transform(X)\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6381010162293341"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Architecture       0.00      0.00      0.00        10\n",
      "                   Arts       0.00      0.00      0.00       107\n",
      "               Business       1.00      0.00      0.01      2020\n",
      "Cars and Transportation       0.00      0.00      0.00       132\n",
      "            Catastrophe       0.00      0.00      0.00       599\n",
      "                Climate       0.00      0.00      0.00        21\n",
      "              Conflicts       0.00      0.00      0.00      1487\n",
      "             Corruption       0.00      0.00      0.00         2\n",
      "                  Crime       0.00      0.00      0.00      1196\n",
      "                Culture       0.00      0.00      0.00      1858\n",
      "                  Dance       0.00      0.00      0.00         5\n",
      "                 Design       0.00      0.00      0.00         4\n",
      "          Digital World       0.00      0.00      0.00        42\n",
      "              Diversity       0.00      0.00      0.00         3\n",
      "              Education       0.00      0.00      0.00       121\n",
      "               Equality       0.00      0.00      0.00        21\n",
      "                   Film       0.00      0.00      0.00       146\n",
      "          Food Security       0.00      0.00      0.00        11\n",
      "      Freedom of Speech       0.00      0.00      0.00        19\n",
      "          Globalization       0.00      0.00      0.00         4\n",
      "                 Health       0.00      0.00      0.00       940\n",
      "                History       0.00      0.00      0.00       205\n",
      "           Human Rights       0.00      0.00      0.00       418\n",
      "             Innovation       0.00      0.00      0.00         2\n",
      "        Law and Justice       0.00      0.00      0.00       570\n",
      "        Learning German       0.00      0.00      0.00        26\n",
      "              Lifestyle       0.00      0.00      0.00       106\n",
      "             Literature       0.00      0.00      0.00        72\n",
      "                  Media       0.00      0.00      0.00       561\n",
      "              Migration       0.00      0.00      0.00        79\n",
      "                  Music       0.00      0.00      0.00       275\n",
      " Nature and Environment       0.96      0.16      0.27      1373\n",
      "                Offbeat       0.00      0.00      0.00        16\n",
      "               Politics       0.32      1.00      0.48      8310\n",
      "          Press Freedom       0.00      0.00      0.00        69\n",
      "               Religion       0.00      0.00      0.00       225\n",
      "            Rule of Law       0.00      0.00      0.00        32\n",
      "                Science       1.00      0.00      0.00       498\n",
      "                 Soccer       0.00      0.00      0.00       131\n",
      "                Society       0.00      0.00      0.00      1547\n",
      "                 Sports       0.82      0.01      0.01      2167\n",
      "             Technology       0.00      0.00      0.00       165\n",
      "              Terrorism       0.00      0.00      0.00       297\n",
      "                Theater       0.00      0.00      0.00         3\n",
      "                  Trade       0.00      0.00      0.00        13\n",
      "                 Travel       0.00      0.00      0.00       464\n",
      "\n",
      "               accuracy                           0.32     26372\n",
      "              macro avg       0.09      0.03      0.02     26372\n",
      "           weighted avg       0.31      0.32      0.17     26372\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 7 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy of the model on Testing Sample Data: 0.17\n",
      "\n",
      "Accuracy values for 5-fold Cross Validation:\n",
      " [0.1693926  0.16265649 0.1646646  0.16671991 0.16377905]\n",
      "\n",
      "Final Average Accuracy of the model: 0.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    " \n",
    "# GaussianNB is used in Binomial Classification\n",
    "# MultinomialNB is used in multi-class classification\n",
    "#clf = GaussianNB()\n",
    "clf = MultinomialNB()\n",
    " \n",
    "# Printing all the parameters of Naive Bayes\n",
    "print(clf)\n",
    " \n",
    "NB=clf.fit(X_train,y_train)\n",
    "prediction=NB.predict(X_test)\n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    " \n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(NB, X , y, cv=5, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 5-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Architecture       0.00      0.00      0.00        10\n",
      "                   Arts       0.00      0.00      0.00       107\n",
      "               Business       0.75      0.52      0.62      2020\n",
      "Cars and Transportation       0.50      0.09      0.15       132\n",
      "            Catastrophe       0.54      0.39      0.45       599\n",
      "                Climate       0.00      0.00      0.00        21\n",
      "              Conflicts       0.45      0.50      0.47      1487\n",
      "             Corruption       0.00      0.00      0.00         2\n",
      "                  Crime       0.54      0.40      0.46      1196\n",
      "                Culture       0.67      0.52      0.59      1858\n",
      "                  Dance       0.00      0.00      0.00         5\n",
      "                 Design       0.00      0.00      0.00         4\n",
      "          Digital World       0.00      0.00      0.00        42\n",
      "              Diversity       0.00      0.00      0.00         3\n",
      "              Education       0.75      0.64      0.69       121\n",
      "               Equality       0.00      0.00      0.00        21\n",
      "                   Film       0.46      0.04      0.08       146\n",
      "          Food Security       0.00      0.00      0.00        11\n",
      "      Freedom of Speech       0.00      0.00      0.00        19\n",
      "          Globalization       0.00      0.00      0.00         4\n",
      "                 Health       0.54      0.73      0.62       940\n",
      "                History       0.40      0.34      0.37       205\n",
      "           Human Rights       0.40      0.17      0.24       418\n",
      "             Innovation       0.00      0.00      0.00         2\n",
      "        Law and Justice       0.37      0.02      0.04       570\n",
      "        Learning German       0.69      0.69      0.69        26\n",
      "              Lifestyle       0.00      0.00      0.00       106\n",
      "             Literature       0.64      0.49      0.55        72\n",
      "                  Media       0.64      0.64      0.64       561\n",
      "              Migration       0.00      0.00      0.00        79\n",
      "                  Music       0.54      0.61      0.57       275\n",
      " Nature and Environment       0.77      0.74      0.75      1373\n",
      "                Offbeat       0.00      0.00      0.00        16\n",
      "               Politics       0.56      0.85      0.67      8310\n",
      "          Press Freedom       0.38      0.17      0.24        69\n",
      "               Religion       0.64      0.57      0.61       225\n",
      "            Rule of Law       0.00      0.00      0.00        32\n",
      "                Science       0.86      0.39      0.54       498\n",
      "                 Soccer       0.00      0.00      0.00       131\n",
      "                Society       0.45      0.13      0.20      1547\n",
      "                 Sports       0.86      0.90      0.87      2167\n",
      "             Technology       0.27      0.07      0.11       165\n",
      "              Terrorism       0.51      0.35      0.42       297\n",
      "                Theater       0.00      0.00      0.00         3\n",
      "                  Trade       0.00      0.00      0.00        13\n",
      "                 Travel       0.77      0.81      0.79       464\n",
      "\n",
      "               accuracy                           0.61     26372\n",
      "              macro avg       0.32      0.26      0.27     26372\n",
      "           weighted avg       0.59      0.61      0.57     26372\n",
      "\n",
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0 1057 ...    0    0   19]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    4 ...    0    0    0]\n",
      " [   0    0   11 ...    0    0  375]]\n",
      "Accuracy of the model on Testing Sample Data: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=46)\n",
    " \n",
    "# Printing all the parameters of KNN\n",
    "print(clf)\n",
    " \n",
    "# Creating the model on Training Data\n",
    "KNN=clf.fit(X_train,y_train)\n",
    "prediction=KNN.predict(X_test)\n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    " \n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "#Accuracy_Values=cross_val_score(KNN, X , y, cv=10, scoring='f1_weighted')\n",
    "#print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "#print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    " \n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "# There is no built-in method to get feature importance in KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.461164  0.364236  0.540574  0.458724  0.521273  0.663672  0.346977   \n",
      "1  0.317105  0.326145  0.563875  0.363254  0.750566  0.658474  0.520716   \n",
      "2  0.421529  0.410348  0.477047  0.469305  0.605007  0.527551  0.384802   \n",
      "3  0.301420  0.388042  0.558668  0.333140  0.717092  0.546199  0.572567   \n",
      "4  0.581959  0.351630  0.290939  0.428102  0.725028  0.597278  0.231202   \n",
      "\n",
      "          7         8         9  ...       292       293       294       295  \\\n",
      "0  0.499663  0.463192  0.555038  ...  0.735587  0.621939  0.467713  0.622281   \n",
      "1  0.637010  0.461076  0.635882  ...  0.526223  0.456953  0.514804  0.561677   \n",
      "2  0.690352  0.544605  0.602065  ...  0.708767  0.491091  0.760175  0.592852   \n",
      "3  0.605582  0.482384  0.500066  ...  0.561804  0.385071  0.542578  0.554821   \n",
      "4  0.405439  0.569468  0.558507  ...  0.555420  0.368912  0.747028  0.672402   \n",
      "\n",
      "        296       297       298       299                Survived  \\\n",
      "0  0.417125  0.530066  0.367954  0.469789               Conflicts   \n",
      "1  0.473964  0.379467  0.339780  0.390200                  Sports   \n",
      "2  0.359752  0.528309  0.344455  0.492774         Law and Justice   \n",
      "3  0.480581  0.493988  0.375403  0.390430                  Sports   \n",
      "4  0.444729  0.520503  0.598185  0.517967  Nature and Environment   \n",
      "\n",
      "   Predicted_Survived  \n",
      "0            Politics  \n",
      "1              Sports  \n",
      "2            Politics  \n",
      "3              Sports  \n",
      "4         Catastrophe  \n",
      "\n",
      "[5 rows x 302 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Architecture       0.00      0.00      0.00        10\n",
      "                   Arts       0.38      0.14      0.20       107\n",
      "               Business       0.69      0.67      0.68      2020\n",
      "Cars and Transportation       0.39      0.23      0.29       132\n",
      "            Catastrophe       0.56      0.48      0.52       599\n",
      "                Climate       0.00      0.00      0.00        21\n",
      "              Conflicts       0.55      0.41      0.47      1487\n",
      "             Corruption       0.00      0.00      0.00         2\n",
      "                  Crime       0.54      0.47      0.50      1196\n",
      "                Culture       0.62      0.66      0.64      1858\n",
      "                  Dance       0.00      0.00      0.00         5\n",
      "                 Design       1.00      0.50      0.67         4\n",
      "          Digital World       0.20      0.05      0.08        42\n",
      "              Diversity       0.00      0.00      0.00         3\n",
      "              Education       0.73      0.61      0.66       121\n",
      "               Equality       0.50      0.05      0.09        21\n",
      "                   Film       0.43      0.28      0.34       146\n",
      "          Food Security       0.25      0.09      0.13        11\n",
      "      Freedom of Speech       0.00      0.00      0.00        19\n",
      "          Globalization       0.00      0.00      0.00         4\n",
      "                 Health       0.65      0.65      0.65       940\n",
      "                History       0.47      0.42      0.44       205\n",
      "           Human Rights       0.37      0.20      0.26       418\n",
      "             Innovation       0.00      0.00      0.00         2\n",
      "        Law and Justice       0.25      0.07      0.11       570\n",
      "        Learning German       0.95      0.73      0.83        26\n",
      "              Lifestyle       0.19      0.03      0.05       106\n",
      "             Literature       0.56      0.49      0.52        72\n",
      "                  Media       0.68      0.63      0.66       561\n",
      "              Migration       0.27      0.11      0.16        79\n",
      "                  Music       0.59      0.54      0.56       275\n",
      " Nature and Environment       0.77      0.73      0.75      1373\n",
      "                Offbeat       0.00      0.00      0.00        16\n",
      "               Politics       0.63      0.83      0.71      8310\n",
      "          Press Freedom       0.20      0.16      0.18        69\n",
      "               Religion       0.61      0.54      0.57       225\n",
      "            Rule of Law       0.33      0.03      0.06        32\n",
      "                Science       0.66      0.59      0.63       498\n",
      "                 Soccer       0.12      0.01      0.01       131\n",
      "                Society       0.41      0.25      0.31      1547\n",
      "                 Sports       0.86      0.93      0.89      2167\n",
      "             Technology       0.29      0.18      0.22       165\n",
      "              Terrorism       0.52      0.42      0.47       297\n",
      "                Theater       0.00      0.00      0.00         3\n",
      "                  Trade       0.00      0.00      0.00        13\n",
      "                 Travel       0.80      0.81      0.81       464\n",
      "\n",
      "               accuracy                           0.64     26372\n",
      "              macro avg       0.39      0.30      0.33     26372\n",
      "           weighted avg       0.61      0.64      0.61     26372\n",
      "\n",
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0   15    0 ...    0    0    0]\n",
      " [   0    0 1357 ...    0    6   21]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    1 ...    0    0    0]\n",
      " [   0    0   17 ...    0    0  376]]\n",
      "Accuracy of the model on Testing Sample Data: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# choose parameter Penalty='l1' or C=1\n",
    "# choose different values for solver 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'\n",
    "clf = LogisticRegression(C=10,penalty='l2', solver='newton-cg')\n",
    " \n",
    "# Printing all the parameters of logistic regression\n",
    "# print(clf)\n",
    " \n",
    "# Creating the model on Training Data\n",
    "LOG=clf.fit(X_train,y_train)\n",
    " \n",
    "# Generating predictions on testing data\n",
    "prediction=LOG.predict(X_test)\n",
    "# Printing sample values of prediction in Testing data\n",
    "TestingData=pd.DataFrame(data=X_test, columns=Predictors)\n",
    "TestingData['Survived']=y_test\n",
    "TestingData['Predicted_Survived']=prediction\n",
    "print(TestingData.head())\n",
    " \n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(prediction, y_test))\n",
    " \n",
    "## Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "## Importing cross validation function from sklearn\n",
    "#from sklearn.model_selection import cross_val_score\n",
    " \n",
    "## Running 10-Fold Cross validation on a given algorithm\n",
    "## Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "#Accuracy_Values=cross_val_score(LOG, X , y, cv=10, scoring='f1_weighted')\n",
    "#print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "#print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Architecture       0.00      0.00      0.00        10\n",
      "                   Arts       0.04      0.06      0.04       107\n",
      "               Business       0.38      0.40      0.39      2020\n",
      "Cars and Transportation       0.04      0.03      0.03       132\n",
      "            Catastrophe       0.21      0.18      0.19       599\n",
      "                Climate       0.00      0.00      0.00        21\n",
      "              Conflicts       0.30      0.33      0.31      1487\n",
      "             Corruption       0.00      0.00      0.00         2\n",
      "                  Crime       0.23      0.20      0.22      1196\n",
      "                Culture       0.37      0.37      0.37      1858\n",
      "                  Dance       0.00      0.00      0.00         5\n",
      "                 Design       0.00      0.00      0.00         4\n",
      "          Digital World       0.04      0.02      0.03        42\n",
      "              Diversity       0.00      0.00      0.00         3\n",
      "              Education       0.46      0.43      0.44       121\n",
      "               Equality       0.00      0.00      0.00        21\n",
      "                   Film       0.20      0.18      0.19       146\n",
      "          Food Security       0.00      0.00      0.00        11\n",
      "      Freedom of Speech       0.19      0.16      0.17        19\n",
      "          Globalization       0.00      0.00      0.00         4\n",
      "                 Health       0.39      0.37      0.38       940\n",
      "                History       0.13      0.10      0.11       205\n",
      "           Human Rights       0.13      0.12      0.12       418\n",
      "             Innovation       0.00      0.00      0.00         2\n",
      "        Law and Justice       0.07      0.06      0.07       570\n",
      "        Learning German       0.67      0.62      0.64        26\n",
      "              Lifestyle       0.00      0.00      0.00       106\n",
      "             Literature       0.25      0.25      0.25        72\n",
      "                  Media       0.41      0.38      0.39       561\n",
      "              Migration       0.04      0.03      0.03        79\n",
      "                  Music       0.36      0.32      0.33       275\n",
      " Nature and Environment       0.53      0.50      0.52      1373\n",
      "                Offbeat       0.14      0.06      0.09        16\n",
      "               Politics       0.56      0.60      0.58      8310\n",
      "          Press Freedom       0.14      0.07      0.09        69\n",
      "               Religion       0.33      0.24      0.28       225\n",
      "            Rule of Law       0.00      0.00      0.00        32\n",
      "                Science       0.25      0.20      0.22       498\n",
      "                 Soccer       0.06      0.03      0.04       131\n",
      "                Society       0.16      0.17      0.16      1547\n",
      "                 Sports       0.71      0.70      0.71      2167\n",
      "             Technology       0.09      0.06      0.07       165\n",
      "              Terrorism       0.13      0.12      0.13       297\n",
      "                Theater       0.00      0.00      0.00         3\n",
      "                  Trade       0.00      0.00      0.00        13\n",
      "                 Travel       0.57      0.49      0.52       464\n",
      "\n",
      "               accuracy                           0.42     26372\n",
      "              macro avg       0.19      0.17      0.18     26372\n",
      "           weighted avg       0.42      0.42      0.42     26372\n",
      "\n",
      "[[  0   0   1 ...   0   0   0]\n",
      " [  2   6   9 ...   0   0   2]\n",
      " [  2   9 804 ...   0   2  30]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   4 ...   0   0   0]\n",
      " [  0   0  32 ...   0   0 227]]\n",
      "Accuracy of the model on Testing Sample Data: 0.42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Trees\n",
    "from sklearn import tree\n",
    "#choose from different tunable hyper parameters\n",
    "clf = tree.DecisionTreeClassifier(max_depth=20,criterion='gini')\n",
    " \n",
    "# Printing all the parameters of Decision Trees\n",
    "print(clf)\n",
    " \n",
    "# Creating the model on Training Data\n",
    "DTree=clf.fit(X_train,y_train)\n",
    "prediction=DTree.predict(X_test)\n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    " \n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(DTree.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(10).plot(kind='barh')\n",
    " \n",
    "# Importing cross validation function from sklearn\n",
    "#from sklearn.model_selection import cross_val_score\n",
    " \n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "#Accuracy_Values=cross_val_score(DTree, X , y, cv=10, scoring='f1_weighted')\n",
    "#print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "#print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),\n",
      "                   learning_rate=0.01, n_estimators=20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ferdinand_t/venv/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "           Architecture       0.00      0.00      0.00        10\n",
      "                   Arts       0.00      0.00      0.00       107\n",
      "               Business       0.00      0.00      0.00      2020\n",
      "Cars and Transportation       0.00      0.00      0.00       132\n",
      "            Catastrophe       0.00      0.00      0.00       599\n",
      "                Climate       0.00      0.00      0.00        21\n",
      "              Conflicts       0.00      0.00      0.00      1487\n",
      "             Corruption       0.00      0.00      0.00         2\n",
      "                  Crime       0.00      0.00      0.00      1196\n",
      "                Culture       0.00      0.00      0.00      1858\n",
      "                  Dance       0.00      0.00      0.00         5\n",
      "                 Design       0.00      0.00      0.00         4\n",
      "          Digital World       0.00      0.00      0.00        42\n",
      "              Diversity       0.00      0.00      0.00         3\n",
      "              Education       0.00      0.00      0.00       121\n",
      "               Equality       0.00      0.00      0.00        21\n",
      "                   Film       0.00      0.00      0.00       146\n",
      "          Food Security       0.00      0.00      0.00        11\n",
      "      Freedom of Speech       0.00      0.00      0.00        19\n",
      "          Globalization       0.00      0.00      0.00         4\n",
      "                 Health       0.00      0.00      0.00       940\n",
      "                History       0.00      0.00      0.00       205\n",
      "           Human Rights       0.00      0.00      0.00       418\n",
      "             Innovation       0.00      0.00      0.00         2\n",
      "        Law and Justice       0.00      0.00      0.00       570\n",
      "        Learning German       0.00      0.00      0.00        26\n",
      "              Lifestyle       0.00      0.00      0.00       106\n",
      "             Literature       0.00      0.00      0.00        72\n",
      "                  Media       0.00      0.00      0.00       561\n",
      "              Migration       0.00      0.00      0.00        79\n",
      "                  Music       0.00      0.00      0.00       275\n",
      " Nature and Environment       0.80      0.10      0.18      1373\n",
      "                Offbeat       0.00      0.00      0.00        16\n",
      "               Politics       0.33      1.00      0.50      8310\n",
      "          Press Freedom       0.00      0.00      0.00        69\n",
      "               Religion       0.00      0.00      0.00       225\n",
      "            Rule of Law       0.00      0.00      0.00        32\n",
      "                Science       0.00      0.00      0.00       498\n",
      "                 Soccer       0.00      0.00      0.00       131\n",
      "                Society       0.00      0.00      0.00      1547\n",
      "                 Sports       0.73      0.50      0.59      2167\n",
      "             Technology       0.00      0.00      0.00       165\n",
      "              Terrorism       0.00      0.00      0.00       297\n",
      "                Theater       0.00      0.00      0.00         3\n",
      "                  Trade       0.00      0.00      0.00        13\n",
      "                 Travel       0.00      0.00      0.00       464\n",
      "\n",
      "               accuracy                           0.36     26372\n",
      "              macro avg       0.04      0.03      0.03     26372\n",
      "           weighted avg       0.21      0.36      0.22     26372\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Accuracy of the model on Testing Sample Data: 0.22\n"
     ]
    }
   ],
   "source": [
    "# Adaboost \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    " \n",
    "# Choosing Decision Tree with 1 level as the weak learner\n",
    "DTC=DecisionTreeClassifier(max_depth=2)\n",
    "clf = AdaBoostClassifier(n_estimators=20, base_estimator=DTC ,learning_rate=0.01)\n",
    " \n",
    "# Printing all the parameters of Adaboost\n",
    "print(clf)\n",
    " \n",
    "# Creating the model on Training Data\n",
    "AB=clf.fit(X_train,y_train)\n",
    "prediction=AB.predict(X_test)\n",
    " \n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction))\n",
    "print(metrics.confusion_matrix(y_test, prediction))\n",
    " \n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    " \n",
    "# Importing cross validation function from sklearn\n",
    "#from sklearn.model_selection import cross_val_score\n",
    " \n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "#Accuracy_Values=cross_val_score(AB, X , y, cv=10, scoring='f1_weighted')\n",
    "#print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "#print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    " \n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "#%matplotlib inline\n",
    "#feature_importances = pd.Series(AB.feature_importances_, index=Predictors)\n",
    "#feature_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8762                     History\n",
       "31542                   Business\n",
       "31543                   Business\n",
       "31544                  Conflicts\n",
       "31545                   Politics\n",
       "                   ...          \n",
       "175654                  Politics\n",
       "175655    Nature and Environment\n",
       "175656                 Conflicts\n",
       "175657                  Business\n",
       "175658                  Politics\n",
       "Name: cleanFocusCategory, Length: 79913, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.loc[:,'cleanFocusCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53541, 300)\n",
      "(53541, 46)\n",
      "(26372, 300)\n",
      "(26372, 46)\n"
     ]
    }
   ],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=DataForML.columns[-1]\n",
    "Predictors=DataForML.columns[:-1]\n",
    " \n",
    "X=DataForML[Predictors].values\n",
    "#y=DataForML[TargetVariable].values\n",
    "y = pd.get_dummies(df_clean['cleanFocusCategory'])\n",
    " \n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, stratify=y)\n",
    " \n",
    "# Sanity check for the sampled data\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Arts</th>\n",
       "      <th>Business</th>\n",
       "      <th>Cars and Transportation</th>\n",
       "      <th>Catastrophe</th>\n",
       "      <th>Climate</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Culture</th>\n",
       "      <th>...</th>\n",
       "      <th>Rule of Law</th>\n",
       "      <th>Science</th>\n",
       "      <th>Soccer</th>\n",
       "      <th>Society</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Terrorism</th>\n",
       "      <th>Theater</th>\n",
       "      <th>Trade</th>\n",
       "      <th>Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31542</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31545</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175656</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175657</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175658</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79913 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Architecture  Arts  Business  Cars and Transportation  Catastrophe  \\\n",
       "8762               0     0         0                        0            0   \n",
       "31542              0     0         1                        0            0   \n",
       "31543              0     0         1                        0            0   \n",
       "31544              0     0         0                        0            0   \n",
       "31545              0     0         0                        0            0   \n",
       "...              ...   ...       ...                      ...          ...   \n",
       "175654             0     0         0                        0            0   \n",
       "175655             0     0         0                        0            0   \n",
       "175656             0     0         0                        0            0   \n",
       "175657             0     0         1                        0            0   \n",
       "175658             0     0         0                        0            0   \n",
       "\n",
       "        Climate  Conflicts  Corruption  Crime  Culture  ...  Rule of Law  \\\n",
       "8762          0          0           0      0        0  ...            0   \n",
       "31542         0          0           0      0        0  ...            0   \n",
       "31543         0          0           0      0        0  ...            0   \n",
       "31544         0          1           0      0        0  ...            0   \n",
       "31545         0          0           0      0        0  ...            0   \n",
       "...         ...        ...         ...    ...      ...  ...          ...   \n",
       "175654        0          0           0      0        0  ...            0   \n",
       "175655        0          0           0      0        0  ...            0   \n",
       "175656        0          1           0      0        0  ...            0   \n",
       "175657        0          0           0      0        0  ...            0   \n",
       "175658        0          0           0      0        0  ...            0   \n",
       "\n",
       "        Science  Soccer  Society  Sports  Technology  Terrorism  Theater  \\\n",
       "8762          0       0        0       0           0          0        0   \n",
       "31542         0       0        0       0           0          0        0   \n",
       "31543         0       0        0       0           0          0        0   \n",
       "31544         0       0        0       0           0          0        0   \n",
       "31545         0       0        0       0           0          0        0   \n",
       "...         ...     ...      ...     ...         ...        ...      ...   \n",
       "175654        0       0        0       0           0          0        0   \n",
       "175655        0       0        0       0           0          0        0   \n",
       "175656        0       0        0       0           0          0        0   \n",
       "175657        0       0        0       0           0          0        0   \n",
       "175658        0       0        0       0           0          0        0   \n",
       "\n",
       "        Trade  Travel  \n",
       "8762        0       0  \n",
       "31542       0       0  \n",
       "31543       0       0  \n",
       "31544       0       0  \n",
       "31545       0       0  \n",
       "...       ...     ...  \n",
       "175654      0       0  \n",
       "175655      0       0  \n",
       "175656      0       0  \n",
       "175657      0       0  \n",
       "175658      0       0  \n",
       "\n",
       "[79913 rows x 46 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "482/482 [==============================] - 4s 6ms/step - loss: 1.5743 - accuracy: 0.5749 - val_loss: 1.2921 - val_accuracy: 0.6112\n",
      "Epoch 2/10\n",
      "482/482 [==============================] - 3s 6ms/step - loss: 1.2528 - accuracy: 0.6241 - val_loss: 1.2237 - val_accuracy: 0.6237\n",
      "Epoch 3/10\n",
      "482/482 [==============================] - 3s 6ms/step - loss: 1.1897 - accuracy: 0.6382 - val_loss: 1.1910 - val_accuracy: 0.6303\n",
      "Epoch 4/10\n",
      "482/482 [==============================] - 3s 7ms/step - loss: 1.1500 - accuracy: 0.6460 - val_loss: 1.1734 - val_accuracy: 0.6360\n",
      "Epoch 5/10\n",
      "482/482 [==============================] - 3s 7ms/step - loss: 1.1204 - accuracy: 0.6515 - val_loss: 1.1669 - val_accuracy: 0.6349\n",
      "Epoch 6/10\n",
      "482/482 [==============================] - 3s 6ms/step - loss: 1.0916 - accuracy: 0.6610 - val_loss: 1.1532 - val_accuracy: 0.6375\n",
      "Epoch 7/10\n",
      "482/482 [==============================] - 3s 6ms/step - loss: 1.0730 - accuracy: 0.6639 - val_loss: 1.1520 - val_accuracy: 0.6353\n",
      "Epoch 8/10\n",
      "482/482 [==============================] - 3s 7ms/step - loss: 1.0535 - accuracy: 0.6681 - val_loss: 1.1463 - val_accuracy: 0.6373\n",
      "Epoch 9/10\n",
      "482/482 [==============================] - 3s 6ms/step - loss: 1.0366 - accuracy: 0.6707 - val_loss: 1.1443 - val_accuracy: 0.6373\n",
      "Epoch 10/10\n",
      "482/482 [==============================] - 3s 6ms/step - loss: 1.0197 - accuracy: 0.6742 - val_loss: 1.1383 - val_accuracy: 0.6413\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#train_size = int(len(df) * .7)\n",
    "#train_posts = df_clean['keywordStrings'][:train_size]\n",
    "#train_tags = df_clean['cleanFocusCategory'][:train_size]\n",
    "\n",
    "#test_posts = df_clean['keywordStrings'][train_size:]\n",
    "#test_tags = df_clean['cleanFocusCategory'][train_size:]\n",
    "\n",
    "#max_words = 20000\n",
    "#tokenize = text.Tokenizer(num_words=max_words, lower= True, char_level=False)\n",
    "#tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "#x_train = features_train\n",
    "#x_test = features_test\n",
    "\n",
    "#x_train = df_clean['keywordStrings'][:train_size]\n",
    "#x_test = df_clean['keywordStrings'][train_size:]\n",
    "\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(y_train)\n",
    "#labels_train = df_clean_dummy[indices_train,:]\n",
    "#labels_test = df_clean_dummy[indices_test,:]\n",
    "\n",
    "#num_classes = np.max(labels_train) + 1\n",
    "#y_train = utils.to_categorical(labels_train, num_classes)\n",
    "#y_test = utils.to_categorical(labels_train, num_classes)\n",
    "\n",
    "num_classes = 46\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(X_train.shape[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "277df8790e3444fd20644b288c4310666d03521f19085f1ded8ea3953ac3e990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
