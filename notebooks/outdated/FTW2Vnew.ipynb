{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# Opening JSON file\n",
    "f = open('/home/ferdinand_t/data/CMS_2010_to_June_2022_ENGLISH.json')\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# df['firstKeyword'] = df['keywords'].apply(lambda x: x[0]['name'] if len(x) != 0 else None)\n",
    "# #df['secondKeyword'] = df['keywords'].apply(lambda x: x[1]['name'] if len(x) > 1 else None)\n",
    "# #df['thirdKeyword'] = df['keywords'].apply(lambda x: x[2]['name'] if len(x) > 2 else None)\n",
    "# #df['fourthKeyword'] = df['keywords'].apply(lambda x: x[3]['name'] if len(x) > 3 else None)\n",
    "\n",
    "df['cleanFocusCategory'] = df['thematicFocusCategory'].apply(lambda x: x['name'] if x is not None else x)\n",
    "\n",
    "# #df = df[['firstKeyword', 'secondKeyword', 'thirdKeyword', 'fourthKeyword', 'thematicFocusCategory', 'cleanFocusCategory']]\n",
    "\n",
    "df = df[['firstKeyword', 'keywordStrings', 'cleanFocusCategory']]\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.dropna()\n",
    "# df_clean['cleanKeywordStrings'] = [' '.join(map(str, l)) for l in df_clean['keywordStrings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vector_size_n_w2v = 5\n",
    "\n",
    "w2v_model = Word2Vec(vector_size=vector_size_n_w2v,\n",
    "                     window=3,\n",
    "                     min_count=1,\n",
    "                     sg=0) # 0=CBOW, 1=Skip-gram\n",
    "\n",
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(df_clean['keywordStrings'])\n",
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.train(df_clean['keywordStrings'], \n",
    "                total_examples=w2v_model.corpus_count, \n",
    "                epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vector_size_n_w2v = 5\n",
    "\n",
    "w2v_model = Word2Vec(df_clean['keywordStrings'],\n",
    "                     vector_size=vector_size_n_w2v,\n",
    "                     window=3,\n",
    "                     min_count=1,\n",
    "                     sg=0, # 0=CBOW, 1=Skip-gram\n",
    "                     epochs=5)\n",
    "\n",
    "print(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec/word2vec_model\")\n",
    "\n",
    "pk.dump(vector_size_n_w2v, open('word2vec/vector_size_w2v_metric.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "words = set(w2v_model.wv.index_to_key )\n",
    "df_clean['Text_vect'] = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
    "                         for ls in df_clean['keywordStrings']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text_vect_avg = []\n",
    "for v in df_clean['Text_vect']:\n",
    "    if v.size:\n",
    "        text_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        text_vect_avg.append(np.zeros(vector_size_n_w2v, dtype=float)) # the same vector size must be used here as for model training\n",
    "        \n",
    "        \n",
    "df_clean['Text_vect_avg'] = text_vect_avg\n",
    "df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_Machine_Learning = pd.DataFrame(text_vect_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_Machine_Learning.columns = ['Element_' + str(i+1) for i in range(0, df_Machine_Learning.shape[1])]\n",
    "df_Machine_Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([df_clean[['cleanFocusCategory', 'keywordStrings']], df_Machine_Learning], axis=1, sort=False)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(df_Machine_Learning, final_df['cleanFocusCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pk.dump(clf, open('clf_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model_reloaded = Word2Vec.load(\"word2vec/word2vec_model\")\n",
    "vector_size_n_reloaded = pk.load(open(\"word2vec/vector_size_w2v_metric.pkl\",'rb'))\n",
    "\n",
    "print(w2v_model_reloaded)\n",
    "print(vector_size_n_reloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
