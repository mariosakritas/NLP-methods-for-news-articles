{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#playing with Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/anya_m/Documents/venv/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/anya_m/Documents/venv/lib/python3.7/site-packages (from gensim) (1.21.6)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/anya_m/Documents/venv/lib/python3.7/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/anya_m/Documents/venv/lib/python3.7/site-packages (from gensim) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__testing_word2vec-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Word vecrors ...\n",
      "conceptnet-numberbatch-17-06-300 (1917247 records): ConceptNet Numberbatch consists of state...\n",
      "fasttext-wiki-news-subwords-300 (999999 records): 1 million word vectors trained on Wikipe...\n",
      "glove-twitter-100 (1193514 records): Pre-trained vectors based on  2B tweets,...\n",
      "glove-twitter-200 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-25 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-50 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-wiki-gigaword-100 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-200 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-300 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-50 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "word2vec-google-news-300 (3000000 records): Pre-trained vectors trained on a part of...\n",
      "word2vec-ruscorpora-300 (184973 records): Word2vec Continuous Skipgram vectors tra...\n"
     ]
    }
   ],
   "source": [
    "info= api.info()\n",
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            model_name,\n",
    "            model_data.get('num_records',-1),\n",
    "            model_data['description'][:40] + '...',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv= api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
     ]
    }
   ],
   "source": [
    "fasttext=api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('holiday', 0.7785156965255737),\n",
       " ('Xmas', 0.7653136253356934),\n",
       " ('Yuletide', 0.7158153057098389),\n",
       " ('Christ_mas', 0.7144487500190735),\n",
       " ('Thanksgiving', 0.7120246887207031),\n",
       " ('Chrismas', 0.7083793878555298),\n",
       " ('Christmas_Eve', 0.7024269104003906),\n",
       " ('Chistmas', 0.7020294070243835),\n",
       " ('Christmastime', 0.6975674033164978),\n",
       " ('Chirstmas', 0.6972543001174927)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('Christmas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chancellors', 0.8404571413993835),\n",
       " ('chancellor', 0.8136057257652283),\n",
       " ('Vice-chancellor', 0.8102172613143921),\n",
       " ('Chancellorship', 0.8024680018424988),\n",
       " ('Vice-Chancellor', 0.8015370965003967),\n",
       " ('Chancellory', 0.7816580533981323),\n",
       " ('Pro-Chancellor', 0.755023181438446),\n",
       " ('then-Chancellor', 0.7378535270690918),\n",
       " ('ex-Chancellor', 0.7313275337219238),\n",
       " ('Provost', 0.7282836437225342)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.most_similar('Chancellor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2842, 0.5597, 0.6355],\n",
      "        [0.4094, 0.1485, 0.0451],\n",
      "        [0.1944, 0.1857, 0.9920],\n",
      "        [0.4882, 0.4896, 0.5229],\n",
      "        [0.2156, 0.3838, 0.7232]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
