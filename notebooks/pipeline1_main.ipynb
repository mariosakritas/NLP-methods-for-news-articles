{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1: Google-To-DW pipeline\n",
    "\n",
    "The aim of this notebook is to be able to answer the questions: Is DW covering what customers want\n",
    "\n",
    "Approach: Extract trending topics on Google and compare to what DW covers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../reports/illustrations/pipeline1.png\" width=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import functions from source folder\n",
    "sys.path.append('../src/') \n",
    "from data.preprocess_keywords import make_cleaned_keywords_df\n",
    "from data.make_datasets import get_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract trending topics from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: specify range and load it?\n",
    "\n",
    "import pandas as pd\n",
    "from pytrends.request import TrendReq as UTrendReq\n",
    "import time\n",
    "from pytrends.exceptions import ResponseError\n",
    "\n",
    "'''Define header to prevent 429 errors from Google'''\n",
    "GET_METHOD='get'\n",
    "headers = {\n",
    "    'authority': 'trends.google.com',\n",
    "    'accept': 'application/json, text/plain, */*',\n",
    "    'accept-language': 'en-GB;q=0.9,en;q=0.8,es;q=0.7',\n",
    "    'content-type': 'application/json;charset=UTF-8',\n",
    "    'cookie': '__utma=10102256.1937595387.1677588086.1677588086.1678441622.2; __utmc=10102256; __utmz=10102256.1678441622.2.2.utmcsr=trends.google.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utmt=1; __utmb=10102256.13.9.1678442016068; CONSENT=YES+GB.en-GB+; HSID=AwrWd8APwv-yBWgzh; SSID=AeXCoum7ArBP5_-aa; APISID=CH4IjtEJhVzXdXGB/AFPE6uuFtOUDiSjnb; SAPISID=FcPgZF83fs0zxFml/Ad59_bwdrgg_kZ4q4; __Secure-1PAPISID=FcPgZF83fs0zxFml/Ad59_bwdrgg_kZ4q4; __Secure-3PAPISID=FcPgZF83fs0zxFml/Ad59_bwdrgg_kZ4q4; SID=TwhPHvTugfJu62Xh-HCJkOIPdoEDrL6q-6Eu9itbEI8mmKw9wzJdgT6c48lYdsNyN4E5xA.; __Secure-1PSID=TwhPHvTugfJu62Xh-HCJkOIPdoEDrL6q-6Eu9itbEI8mmKw9mFTrJ0j2r8zMRcq3v-A7Dg.; __Secure-3PSID=TwhPHvTugfJu62Xh-HCJkOIPdoEDrL6q-6Eu9itbEI8mmKw9xQIlYIR6TyZD2qXkeuopSA.; OGPC=19031986-1:; AEC=ARSKqsLpZW_sbZN2NdijlA8HPzuRHa1TPtYLHLGgaOIZpt8oJZL9PYZZYQ; SEARCH_SAMESITE=CgQI4ZcB; 1P_JAR=2023-03-10-09; NID=511=bYRTpZST7bJyL0z371h4Y79EMA1j9QqQFUpi8vJsSmiWdINx5gKruSDljEBAFfs9FYsxRrmP7vulT_MdtU2xEXQSW837vsgNY9s0i2WZAeFETmMEDrju3d_HgA2Wxy5DrFrIOaOiFu6LkpD7pY4wF4qrMZ38BzvW4NkYX_fUI7bFzHXsg24iHara1hPmPIXOSl6wQgsssfGHUntOI9PgY_eXaAEJbY7VgTr1hjNvEDlFSYOuzLvHSzo9kX9ALXA5-WOICbuLdAucZc3hJKo1dUKM51JCkzLsUHm99MWA86Icz-dmMW8ybQZhEUd2YgsBHHn5MV8uSVpcZ53n4_KL7r6sOpfWZ0ZXairmL3NH-hHz4Vyq; _gid=GA1.3.1682047475.1678441583; OTZ=6935626_48_48_123900_44_436380; _gat_gtag_UA_4401283=1; _ga=GA1.3.1937595387.1677588086; SIDCC=AFvIBn_I_znBUYDEoxfE1jUbrp_F8T607DZhlzI9o_gQoZmA4OxNjglOrH8Q8er3Cv4uzoWYkX9Z; __Secure-1PSIDCC=AFvIBn_Nhc9nywxJ_UrRYogvErcX48ygHEiBzjRRZtPe-mIwBTe_M7UbvKR4d-rAuhYyGJi-Dm0; __Secure-3PSIDCC=AFvIBn8vpeAOp5e0oAWBAETEzSClsyQlm3vQJhAQP7T7Z51q1K7zHDm_-CSGFEPasFw0sRHoJDU; _ga_VWZPXDNJJB=GS1.1.1678441583.2.1.1678442016.0.0.0',\n",
    "    'origin': 'https://trends.google.com',\n",
    "    'referer': 'https://trends.google.com/trends/explore?date=now%201-d&q=Adele&hl=en-GB',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"110\", \"Not A(Brand\";v=\"24\", \"Google Chrome\";v=\"110\"',\n",
    "    'sec-ch-ua-arch': '\"x86\"',\n",
    "    'sec-ch-ua-bitness': '\"64\"',\n",
    "    'sec-ch-ua-full-version': '\"110.0.5481.177\"',\n",
    "    'sec-ch-ua-full-version-list': '\"Chromium\";v=\"110.0.5481.177\", \"Not A(Brand\";v=\"24.0.0.0\", \"Google Chrome\";v=\"110.0.5481.177\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-model': '',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-ch-ua-platform-version': '\"13.2.1\"',\n",
    "    'sec-ch-ua-wow64': '?0',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',\n",
    "    'x-client-data': 'CIq2yQEIprbJAQjEtskBCKmdygEIkufKAQiVocsBCPyqzAEI9/XMAQib/swBCI6MzQEIlZbNAQiols0BCOGXzQEI5JfNAQjzl80BCMyYzQEI2JjNAQjzmc0BCLSazQEI0uGsAg==',\n",
    "}\n",
    "\n",
    "''' Implement header inside new TrendReq class'''\n",
    "class TrendReq(UTrendReq):\n",
    "    def _get_data(self, url, method=GET_METHOD, trim_chars=0, **kwargs):\n",
    "        return super()._get_data(url, method=GET_METHOD, trim_chars=trim_chars, headers=headers, **kwargs)\n",
    "\n",
    "def get_daily_trending_searches(filepath = '../data/interim/',start_date = '20190101', end_date = '20190101', geography=''):\n",
    "    '''Takes a start date, end date and geography to retrieve daily Google trending searches during that date range in that geography\n",
    "    also puts that dataframe inside a json file in the folder indicated by the filepath'''\n",
    "\n",
    "    daily_trending_searches = pd.DataFrame()\n",
    "\n",
    "    pytrend = TrendReq(                    \n",
    "    # proxies=['https://34.203.233.13:80','https://35.201.123.31:880'], \n",
    "    # #hl='en-US', tz=360, timeout=(10,25)\n",
    "    retries=2, backoff_factor=0.1, requests_args={'verify':False})\n",
    "\n",
    "    for i in [dr.strftime('%Y-%m-%d') for dr in pd.date_range(start_date,end_date)]:\n",
    "        try:\n",
    "            pytrend.build_payload(kw_list=[''], timeframe=i + ' ' + i, geo=geography)\n",
    "            df_rt_test = pytrend.related_topics()\n",
    "            data = df_rt_test['']['rising']\n",
    "            time.sleep(12)\n",
    "            print(i)\n",
    "        except ResponseError:\n",
    "            print('Timeout')\n",
    "        daily_trending_searches = daily_trending_searches.append(data)\n",
    "    daily_trending_searches.reset_index(drop=True, inplace=True)\n",
    "    daily_trending_searches['date'] = daily_trending_searches['link'].apply(lambda x: x.split('&')[1].split('date=')[1].split('+')[0])\n",
    "    daily_trending_searches['location'] = geography if geography != '' else 'World'\n",
    "    location = geography if geography != '' else 'World' \n",
    "    # storing the data in JSON format\n",
    "    daily_trending_searches.to_json(filepath+start_date+'_'+end_date+'_'+location+'_daily_trending_searches.json', orient = 'split', compression = 'infer', index = 'true')\n",
    "    \n",
    "    return daily_trending_searches\n",
    "\n",
    "\n",
    "# Load Google data\n",
    "df_google = get_daily_trending_searches(filepath = '../data/interim/',start_date = '20190101', end_date = '20190101', geography='')\n",
    "#df_google = pd.read_json(filepath+start_date+'_'+end_date+'_daily_trending_searches.json', orient ='split', compression = 'infer')\n",
    "\n",
    "#TODO: Drop from df_google topic type = 'Topic' --> too broad and possibly repetitive vs previous trending search keyword"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify wanted time range\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2022-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data file in specific date range\n",
    "clean_data_file = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "\n",
    "# Generates the clean data file if it does not exist\n",
    "if os.path.isfile(clean_data_file) == False:\n",
    "\n",
    "    # Path to raw data\n",
    "    data_file = '../data/raw/CMS_2010_to_June_2022_ENGLISH.json'\n",
    "\n",
    "    # Load and extract data within time range\n",
    "    df_subset = get_data(data_file, start_date, end_date)\n",
    "\n",
    "    # Cleans keywords and saves data as a dataframe\n",
    "    make_cleaned_keywords_df(df_subset, start_date, end_date)\n",
    "\n",
    "\n",
    "# Loads the clean data file\n",
    "df_dw = pd.read_json(clean_data_file, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lastModifiedDate</th>\n",
       "      <th>Date</th>\n",
       "      <th>keywordStrings</th>\n",
       "      <th>cleanFocusParentCategory</th>\n",
       "      <th>cleanFocusCategory</th>\n",
       "      <th>teaser</th>\n",
       "      <th>keywordStringsCleanAfterFuzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60278</th>\n",
       "      <td>46912921</td>\n",
       "      <td>2019-01-01T03:57:28.904Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[NASA, OSIRIS-REx, Bennu, asteroid]</td>\n",
       "      <td>Science</td>\n",
       "      <td>Science</td>\n",
       "      <td>The OSIRIS-REx spacecraft had arrived at the l...</td>\n",
       "      <td>[nasa, osiris-rex, bennu, asteroid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60279</th>\n",
       "      <td>46911356</td>\n",
       "      <td>2019-01-01T06:11:50.527Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[English Channel, migration, boats, illegal im...</td>\n",
       "      <td>Law and Justice</td>\n",
       "      <td>Law and Justice</td>\n",
       "      <td>The UK is withdrawing patrol ships from overse...</td>\n",
       "      <td>[english channel, migration, boats, illegal im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60280</th>\n",
       "      <td>46909694</td>\n",
       "      <td>2019-01-01T06:14:35.563Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[Brazil, Jair Bolsonaro, Chicago economics, Ha...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Brazil is inaugurating President Jair Bolsonar...</td>\n",
       "      <td>[brazil, jair bolsonaro, chicago economics, ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id          lastModifiedDate       Date  \\\n",
       "60278  46912921  2019-01-01T03:57:28.904Z 2019-01-01   \n",
       "60279  46911356  2019-01-01T06:11:50.527Z 2019-01-01   \n",
       "60280  46909694  2019-01-01T06:14:35.563Z 2019-01-01   \n",
       "\n",
       "                                          keywordStrings  \\\n",
       "60278                [NASA, OSIRIS-REx, Bennu, asteroid]   \n",
       "60279  [English Channel, migration, boats, illegal im...   \n",
       "60280  [Brazil, Jair Bolsonaro, Chicago economics, Ha...   \n",
       "\n",
       "      cleanFocusParentCategory cleanFocusCategory  \\\n",
       "60278                  Science            Science   \n",
       "60279          Law and Justice    Law and Justice   \n",
       "60280                 Politics           Politics   \n",
       "\n",
       "                                                  teaser  \\\n",
       "60278  The OSIRIS-REx spacecraft had arrived at the l...   \n",
       "60279  The UK is withdrawing patrol ships from overse...   \n",
       "60280  Brazil is inaugurating President Jair Bolsonar...   \n",
       "\n",
       "                            keywordStringsCleanAfterFuzz  \n",
       "60278                [nasa, osiris-rex, bennu, asteroid]  \n",
       "60279  [english channel, migration, boats, illegal im...  \n",
       "60280  [brazil, jair bolsonaro, chicago economics, ha...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display clean data\n",
    "# cleanFocusParentCategory = Only the parent category (from src/preprocess_keywords.py function: clean_categories)\n",
    "# cleanFocusCategory = all categories\n",
    "# keywordStrings = raw keywords\n",
    "# keywordStringsCleanAfterFuzz = Cleaned keywords (from src/preprocess_keywords.py function: make_cleaned_keywords_df)\n",
    "# lastModifiedDate = raw date\n",
    "# Date = just the date (in datetime format)\n",
    "df_dw.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Google dataset to DW timerange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date range in data\n",
    "start_date_dw = pd.to_datetime(df_dw['Date']).min()\n",
    "end_date_dw = pd.to_datetime(df_dw['Date']).max()\n",
    "\n",
    "# Remove rows witn no category\n",
    "df_dw.dropna(subset=['cleanFocusCategory'], inplace = True)\n",
    "df_dw.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Keeps only google data within DW data date range\n",
    "df_google.sort_values(by ='date', inplace = True) \n",
    "mask = (pd.to_datetime(df_google['date']) > start_date_dw) & (pd.to_datetime(df_google['date']) <= end_date_dw)\n",
    "df_google_subset = df_google.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: map google keywords to DW category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare trending topics and DW covered categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
