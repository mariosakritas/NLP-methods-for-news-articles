{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1: Google-To-DW pipeline\n",
    "\n",
    "The aim of this notebook is to be able to answer the questions: Is DW covering what customers want\n",
    "\n",
    "Approach: Extract trending topics on Google and compare to what DW covers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../reports/illustrations/pipeline1.png\" width=800 />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried 2 different approaches:\n",
    "\n",
    "**Approach 1**: we used pre-trained models such as Chat GPT and zero-shot learning. \\\n",
    "This approach was overal less effective. Our attempts can be found in pipeline2_playground_approach1_*.ipynb\n",
    "\n",
    "**Approach 2**: we trained our own models \\\n",
    "The most performing models are sumarised here. Our other attempts can be found in pipeline2_playground_approach2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../reports/illustrations/pipeline2_approaches.png\" width=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import functions from source folder\n",
    "sys.path.append('../src/') \n",
    "from data.preprocess_keywords import make_cleaned_keywords_df\n",
    "from data.make_datasets import get_data, get_daily_trending_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify wanted time range\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2019-02-01'\n",
    "\n",
    "# Where data files will be stored\n",
    "path_to_data_files = '../data/interim/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract trending topics from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts trending topic from Google if the file does not exist, else loads it\n",
    "# If error with the number of requests, change the header in make_datasets.py \n",
    "# (https://stackoverflow.com/questions/50571317/pytrends-the-request-failed-google-returned-a-response-with-code-429#:~:text=I%20am%20trustworthy.-,Solution,Visit%20the%20Google%20Trend%20page%20and%20perform%20a%20search%20for,-a%20trend%3B%20it)\n",
    "\n",
    "google_file = path_to_data_files + start_date + '_' + end_date + '_World_daily_trending_searches.json'\n",
    "\n",
    "if os.path.isfile(google_file) == False:\n",
    "    df_google = get_daily_trending_searches(path_to_data_files, start_date, end_date = end_date)\n",
    "else:\n",
    "    df_google = pd.read_json(google_file, orient ='split', compression = 'infer') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data file in specific date range\n",
    "clean_data_file = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "\n",
    "# Generates the clean data file if it does not exist\n",
    "if os.path.isfile(clean_data_file) == False:\n",
    "\n",
    "    # Path to raw data\n",
    "    data_file = '../data/raw/CMS_2010_to_June_2022_ENGLISH.json'\n",
    "\n",
    "    # Load and extract data within time range\n",
    "    df_subset = get_data(data_file, start_date, end_date)\n",
    "\n",
    "    # Cleans keywords and saves data as a dataframe\n",
    "    make_cleaned_keywords_df(df_subset, start_date, end_date)\n",
    "\n",
    "\n",
    "# Loads the clean data file\n",
    "df_dw = pd.read_json(clean_data_file, orient ='split', compression = 'infer')\n",
    "\n",
    "# Remove rows witn no category\n",
    "df_dw.dropna(subset=['cleanFocusCategory'], inplace = True)\n",
    "df_dw.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: map google keywords to DW category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lastModifiedDate</th>\n",
       "      <th>Date</th>\n",
       "      <th>keywordStrings</th>\n",
       "      <th>cleanFocusParentCategory</th>\n",
       "      <th>cleanFocusCategory</th>\n",
       "      <th>teaser</th>\n",
       "      <th>keywordStringsCleanAfterFuzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46912921</td>\n",
       "      <td>2019-01-01T03:57:28.904Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[NASA, OSIRIS-REx, Bennu, asteroid]</td>\n",
       "      <td>Science</td>\n",
       "      <td>Science</td>\n",
       "      <td>The OSIRIS-REx spacecraft had arrived at the l...</td>\n",
       "      <td>[nasa, osiris-rex, bennu, asteroid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46911356</td>\n",
       "      <td>2019-01-01T06:11:50.527Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[English Channel, migration, boats, illegal im...</td>\n",
       "      <td>Law and Justice</td>\n",
       "      <td>Law and Justice</td>\n",
       "      <td>The UK is withdrawing patrol ships from overse...</td>\n",
       "      <td>[english channel, migration, boats, illegal im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46909694</td>\n",
       "      <td>2019-01-01T06:14:35.563Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[Brazil, Jair Bolsonaro, Chicago economics, Ha...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Brazil is inaugurating President Jair Bolsonar...</td>\n",
       "      <td>[brazil, jair bolsonaro, chicago economics, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46912694</td>\n",
       "      <td>2019-01-01T08:26:11.599Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[Japan, Tokyo, Harajuku, attack]</td>\n",
       "      <td>Law and Justice</td>\n",
       "      <td>Crime</td>\n",
       "      <td>A man with an \"intent to murder\" has driven a ...</td>\n",
       "      <td>[japan, tokyo, harajuku, attack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46910092</td>\n",
       "      <td>2019-01-01T09:05:00.736Z</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>[Asia, Bangladesh, elections, Kamal Hossain, S...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Politics</td>\n",
       "      <td>In an exclusive interview with DW, Kamal Hossa...</td>\n",
       "      <td>[asia, bangladesh, elections, kamal hossain, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          lastModifiedDate       Date  \\\n",
       "0  46912921  2019-01-01T03:57:28.904Z 2019-01-01   \n",
       "1  46911356  2019-01-01T06:11:50.527Z 2019-01-01   \n",
       "2  46909694  2019-01-01T06:14:35.563Z 2019-01-01   \n",
       "3  46912694  2019-01-01T08:26:11.599Z 2019-01-01   \n",
       "4  46910092  2019-01-01T09:05:00.736Z 2019-01-01   \n",
       "\n",
       "                                      keywordStrings cleanFocusParentCategory  \\\n",
       "0                [NASA, OSIRIS-REx, Bennu, asteroid]                  Science   \n",
       "1  [English Channel, migration, boats, illegal im...          Law and Justice   \n",
       "2  [Brazil, Jair Bolsonaro, Chicago economics, Ha...                 Politics   \n",
       "3                   [Japan, Tokyo, Harajuku, attack]          Law and Justice   \n",
       "4  [Asia, Bangladesh, elections, Kamal Hossain, S...                 Politics   \n",
       "\n",
       "  cleanFocusCategory                                             teaser  \\\n",
       "0            Science  The OSIRIS-REx spacecraft had arrived at the l...   \n",
       "1    Law and Justice  The UK is withdrawing patrol ships from overse...   \n",
       "2           Politics  Brazil is inaugurating President Jair Bolsonar...   \n",
       "3              Crime  A man with an \"intent to murder\" has driven a ...   \n",
       "4           Politics  In an exclusive interview with DW, Kamal Hossa...   \n",
       "\n",
       "                        keywordStringsCleanAfterFuzz  \n",
       "0                [nasa, osiris-rex, bennu, asteroid]  \n",
       "1  [english channel, migration, boats, illegal im...  \n",
       "2  [brazil, jair bolsonaro, chicago economics, ha...  \n",
       "3                   [japan, tokyo, harajuku, attack]  \n",
       "4  [asia, bangladesh, elections, kamal hossain, s...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data from DW\n",
    "df_dw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>formattedValue</th>\n",
       "      <th>link</th>\n",
       "      <th>topic_mid</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174300</td>\n",
       "      <td>Breakout</td>\n",
       "      <td>/trends/explore?q=/m/02vxn&amp;date=2019-01-02+201...</td>\n",
       "      <td>/m/02vxn</td>\n",
       "      <td>Film</td>\n",
       "      <td>Topic</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>39500</td>\n",
       "      <td>Breakout</td>\n",
       "      <td>/trends/explore?q=/m/014dgf&amp;date=2019-01-02+20...</td>\n",
       "      <td>/m/014dgf</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Topic</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39700</td>\n",
       "      <td>Breakout</td>\n",
       "      <td>/trends/explore?q=/m/0jg24&amp;date=2019-01-02+201...</td>\n",
       "      <td>/m/0jg24</td>\n",
       "      <td>Image</td>\n",
       "      <td>Topic</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>39750</td>\n",
       "      <td>Breakout</td>\n",
       "      <td>/trends/explore?q=/m/0mgkg&amp;date=2019-01-02+201...</td>\n",
       "      <td>/m/0mgkg</td>\n",
       "      <td>Amazon.com</td>\n",
       "      <td>E-commerce company</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>39900</td>\n",
       "      <td>Breakout</td>\n",
       "      <td>/trends/explore?q=/m/0glpjll&amp;date=2019-01-02+2...</td>\n",
       "      <td>/m/0glpjll</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Social networking service</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     value formattedValue                                               link  \\\n",
       "0   174300       Breakout  /trends/explore?q=/m/02vxn&date=2019-01-02+201...   \n",
       "24   39500       Breakout  /trends/explore?q=/m/014dgf&date=2019-01-02+20...   \n",
       "23   39700       Breakout  /trends/explore?q=/m/0jg24&date=2019-01-02+201...   \n",
       "22   39750       Breakout  /trends/explore?q=/m/0mgkg&date=2019-01-02+201...   \n",
       "21   39900       Breakout  /trends/explore?q=/m/0glpjll&date=2019-01-02+2...   \n",
       "\n",
       "     topic_mid topic_title                 topic_type       date location  \n",
       "0     /m/02vxn        Film                      Topic 2019-01-02    World  \n",
       "24   /m/014dgf       Sales                      Topic 2019-01-02    World  \n",
       "23    /m/0jg24       Image                      Topic 2019-01-02    World  \n",
       "22    /m/0mgkg  Amazon.com         E-commerce company 2019-01-02    World  \n",
       "21  /m/0glpjll   Instagram  Social networking service 2019-01-02    World  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data from Google\n",
    "df_google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare trending topics and DW covered categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
