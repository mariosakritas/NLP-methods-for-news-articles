{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process as pr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob # to convert plurals to singulars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RapidFuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load set of DW keywords before fuzzyWuzzy into the file\n",
    "uni_kw=pd.read_csv('../data/interim/out_2019-2021_keywords_before_FuzzyWuzzy.csv', names = ['ind', 'keyword'], header=0) \n",
    "#unique_keywords=uni_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32704\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>state repression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>climate consensus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Canary Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Angela I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind            keyword\n",
       "0    0            malware\n",
       "1    1   state repression\n",
       "2    2  climate consensus\n",
       "3    3     Canary Islands\n",
       "4    4           Angela I"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(uni_kw))\n",
    "uni_kw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 1: all in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  32704\n",
      "all in lower case:  30385\n"
     ]
    }
   ],
   "source": [
    "keywords = list(uni_kw['keyword'])\n",
    "keywords_clean = list(set(uni_kw['keyword'].str.lower())) # Cleaning: Write all in lower case\n",
    "\n",
    "print('original: ', len(keywords))\n",
    "print('all in lower case: ', len(keywords_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 2: split keywords that were not split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after splitting: 30404\n"
     ]
    }
   ],
   "source": [
    "substring = ', '\n",
    "\n",
    "list_multikw = [kw for kw in keywords_clean if substring in kw] # keywords that did not get split\n",
    "new_keywords = [kw.split(substring) for kw in list_multikw] # make a list of new keywords (the splited multi kw)\n",
    "\n",
    "# Flatten list of list of new keywords\n",
    "flat_new_keywords = [item for sublist in new_keywords for item in sublist]\n",
    "flat_new_keywords.remove('') # remove empty values\n",
    "\n",
    "# Remove the non-seperated keywords\n",
    "for el in list_multikw:\n",
    "    keywords_clean.remove(el)\n",
    "\n",
    "# Add the seperated ones\n",
    "keywords_clean = keywords_clean + flat_new_keywords\n",
    "\n",
    "print('after splitting:', len(keywords_clean)) # number is higher because split long keyowrds into multiple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 3: remove '\\u2002' and '.' and '\\xa0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after removing u2022: 30320\n"
     ]
    }
   ],
   "source": [
    "keywords_clean = list(set([kw.replace('\\u2002','') for kw in keywords_clean]))\n",
    "keywords_clean = list(set([kw.replace('.','') for kw in keywords_clean]))\n",
    "keywords_clean = list(set([kw.replace('\\xa0',' ') for kw in keywords_clean]))\n",
    "keywords_clean.remove('') # TODO understand why there is an empty row\n",
    "print('after removing u2022:', len(keywords_clean))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute similarity of each keyword of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ratio_array= pr.cdist(keywords_clean, keywords_clean, score_cutoff = 90)\n",
    "len(ratio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (30321, 30321), indices imply (30321, 30320)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21818/193908231.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib64/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                     \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m                 )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib64/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib64/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (30321, 30321), indices imply (30321, 30320)"
     ]
    }
   ],
   "source": [
    "df_array = pd.DataFrame(ratio_array, columns = keywords_clean)\n",
    "df_array.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract similar keywords based on this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4979"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of non zero values in each row\n",
    "nb_non_zero = np.count_nonzero(np.asarray(ratio_array), axis=1) \n",
    "\n",
    "# Save indices of rows with more than 1 non-zero value\n",
    "indices_correlating_rows = [i for i, el in enumerate(list(nb_non_zero)) if el>1]\n",
    "len(indices_correlating_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trans-atlantic relations', 'saif al-islam', 'phil spector']\n",
      "['zaikur rehman lakhvi', 'chuck schumer']\n",
      "['terror list', 'syrian war']\n",
      "['bosporus', '#speakup! barometer']\n",
      "['global media forum 2018', 'euros', 'etna']\n",
      "['united nations', 'repurposing']\n",
      "['737max', 'emoglyphs']\n",
      "['aphrodisiacs', 'bushido']\n",
      "['skripals', 'lodz']\n",
      "['synagoge', 'blasphemey']\n",
      "['vineyards', 'hawaii']\n",
      "['deep-sea mining', 'la soufriere']\n",
      "['tortured', 'dorian']\n",
      "['reeducation camps', 'agent orange', 'big tech']\n",
      "['north rhine westphalia', 'us house of represntatives', 'infectious diseases', 'travel literature']\n",
      "['the sun', 'khalid sheikh mohammed']\n",
      "['halyna hutchinson', 'space mission']\n",
      "['spelling bee', 'james lawrence']\n",
      "['berlin marathon', 'quantative easing']\n",
      "['minsk protests', 'german weather service']\n",
      "['helen clark', 'kirakira+']\n",
      "['azza\\xa0karam', 'cultural policy in germany']\n",
      "['demonstrations;violence', 'bath houses']\n",
      "['the left party', 'electricity outages']\n",
      "['deep-sea mining', 'la soufriere']\n",
      "['demilitarized zone', 'myanmar ethnic groups']\n",
      "['wheelchair basketball', 're:publica']\n",
      "['satellite navigation', 'wassim mukdad', 'employee protest']\n",
      "['spacex', 'blood']\n",
      "['tönnies', 'crises']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,30):\n",
    "    list_similar_words = [keyword for val, keyword in zip(list(df_array.iloc[indices_correlating_rows[i]]), keywords_clean) if val!=0]\n",
    "    print(list_similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to remove singlulars from those words (don't do before because too many errors, e.g., us = u, thomas = thoma)\n",
    "keywords_clean = [' '.join(list(TextBlob(kw).words.singularize())) for kw in keywords_clean]\n",
    "print('after removing u2022:', len(keywords_clean))\n",
    "keywords_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
