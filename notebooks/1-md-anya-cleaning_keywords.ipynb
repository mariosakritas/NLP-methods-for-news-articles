{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to clean the keyword column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import itertools # to flatten lists of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('../data/raw/CMS_2010_to_June_2022_ENGLISH.json')\n",
    "  \n",
    "# returns JSON object as a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "# convert to data frame\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'shortTitle', 'text', 'teaser', 'shortTeaser', 'kicker',\n",
       "       'regions', 'keywords', 'keywordStrings', 'thematicFocusCategory',\n",
       "       'navigations', 'categories', 'departments', 'firstPublicationDate',\n",
       "       'lastModifiedDate', 'contentDate', 'relatedAutoTopics', 'contentLinks',\n",
       "       'articles', 'isOpinion', 'geographicLocations', 'contentAssociations',\n",
       "       'mainContentImageLink', 'images', 'externalLinks', 'topStory',\n",
       "       'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = list(df.keywordStrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used mainly for visualisation, get indices of keywords with a certain substring\n",
    "def get_items_with_substring(lst_lst_keywords, substring):\n",
    "    indices = [i for i, lst_kw in enumerate(lst_lst_keywords) if any(list(map(lambda x: substring in x, lst_kw)))]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 1: put everything in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_lower = [list(map(str.casefold, x)) for x in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['DRC', 'M23', 'FDLR', 'Rwanda', 'Susan Rice', 'UN security council']\n",
      "after:  ['drc', 'm23', 'fdlr', 'rwanda', 'susan rice', 'un security council']\n"
     ]
    }
   ],
   "source": [
    "# for visualisation only (can remove later on)\n",
    "print('before:', keywords[0])\n",
    "print('after: ', keywords_lower[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 2: split keywords that haven't been split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['#speakup! barometer', 'freedom of speech, press freedom, freedom of expression', 'ghana']\n",
      "after:  ['#speakup! barometer', 'freedom of speech', 'press freedom', 'freedom of expression', 'ghana']\n"
     ]
    }
   ],
   "source": [
    "# What we are looking for to split by\n",
    "substring = ', '\n",
    "\n",
    "# Split keywords: kw.split splits the keyword in a list of multiple keywords based on substring, itertools.chain flattens the list of lists\n",
    "keywords_lower_split = [list(itertools.chain(*[kw.split(substring) for kw in lst_kw])) for lst_kw in keywords_lower]\n",
    "\n",
    "# for visualisation only (can remove later on)\n",
    "items_with_unsplit_keywords = get_items_with_substring(keywords_lower, substring)\n",
    "print('before:', keywords_lower[items_with_unsplit_keywords[1]])\n",
    "print('after: ', keywords_lower_split[items_with_unsplit_keywords[1]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 3: remove unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '\\u2002' and '.', replace '\\xa0' with space\n",
    "keywords_lower_split_clean = keywords_lower_split\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('\\u2002', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('.', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('\\xa0', ' '), lst_kw)) for lst_kw in keywords_lower_split_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['usa', 'trade pact', 'ethiopia', 'agoa', 'mali', '\\u2002guinea']\n",
      "after:  ['usa', 'trade pact', 'ethiopia', 'agoa', 'mali', 'guinea']\n"
     ]
    }
   ],
   "source": [
    "# for visualisation only (can remove later on)\n",
    "items_with_unwanted_characters = get_items_with_substring(keywords_lower, substring = '\\u2002')\n",
    "print('before:', keywords_lower_split[items_with_unwanted_characters[0]])\n",
    "print('after: ', keywords_lower_split_clean[items_with_unwanted_characters[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 4: other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tropical tiger asian bush mosquito  mosquito', 'diseases']\n"
     ]
    }
   ],
   "source": [
    "items = [i for i,lst_kw in enumerate(keywords_lower) if any(list(map(lambda x: 'tropical tiger' in x, lst_kw)))]\n",
    "print(keywords_lower_split_clean[items[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing olympics speedskating doping gold medal']\n"
     ]
    }
   ],
   "source": [
    "items = [i for i,lst_kw in enumerate(keywords_lower) if any(list(map(lambda x: 'beijing olympics speedskating' in x, lst_kw)))]\n",
    "print(keywords_lower_split_clean[items[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allies of donald trump are set to challenge the election result in a longshot that is almost certain to fail']\n"
     ]
    }
   ],
   "source": [
    "items = [i for i,lst_kw in enumerate(keywords_lower) if any(list(map(lambda x: 'allies of donald' in x, lst_kw)))]\n",
    "print(keywords_lower_split_clean[items[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
