{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to clean the keyword column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import itertools # to flatten lists of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('../data/raw/CMS_2010_to_June_2022_ENGLISH.json')\n",
    "  \n",
    "# returns JSON object as a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "# convert to data frame\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'shortTitle', 'text', 'teaser', 'shortTeaser', 'kicker',\n",
       "       'regions', 'keywords', 'keywordStrings', 'thematicFocusCategory',\n",
       "       'navigations', 'categories', 'departments', 'firstPublicationDate',\n",
       "       'lastModifiedDate', 'contentDate', 'relatedAutoTopics', 'contentLinks',\n",
       "       'articles', 'isOpinion', 'geographicLocations', 'contentAssociations',\n",
       "       'mainContentImageLink', 'images', 'externalLinks', 'topStory',\n",
       "       'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = list(df.keywordStrings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used mainly for visualisation, get indices of keywords with a certain substring\n",
    "def get_items_with_substring(lst_lst_keywords, substring):\n",
    "    indices = [i for i, lst_kw in enumerate(lst_lst_keywords) if any(list(map(lambda x: substring in x, lst_kw)))]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 1: put everything in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_lower = [list(map(str.casefold, x)) for x in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['DRC', 'M23', 'FDLR', 'Rwanda', 'Susan Rice', 'UN security council']\n",
      "after:  ['drc', 'm23', 'fdlr', 'rwanda', 'susan rice', 'un security council']\n"
     ]
    }
   ],
   "source": [
    "# for visualisation only (can remove later on)\n",
    "print('before:', keywords[0])\n",
    "print('after: ', keywords_lower[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 2: split keywords that haven't been split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['southeast asia', 'world economic forum', 'asean', 'digitization', 'hanoi, vietnam']\n",
      "after:  ['southeast asia', 'world economic forum', 'asean', 'digitization', 'hanoi', 'vietnam'] \n",
      "\n",
      "before: ['#speakup! barometer', 'freedom of speech, press freedom, freedom of expression', 'ghana']\n",
      "after:  ['#speakup! barometer', 'freedom of speech', 'press freedom', 'freedom of expression', 'ghana'] \n",
      "\n",
      "before: ['ghana', 'africa', 'freedom of speech, press freedom, freedom of expression']\n",
      "after:  ['ghana', 'africa', 'freedom of speech', 'press freedom', 'freedom of expression'] \n",
      "\n",
      "before: ['night grooves, talkshow, music, kim fisher, wigald boning, haus schminke, deutsche welle, dw']\n",
      "after:  ['night grooves', 'talkshow', 'music', 'kim fisher', 'wigald boning', 'haus schminke', 'deutsche welle', 'dw'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What we are looking for to split by\n",
    "substring = ', '\n",
    "\n",
    "# Split keywords: kw.split splits the keyword in a list of multiple keywords based on substring, itertools.chain flattens the list of lists\n",
    "keywords_lower_split = [list(itertools.chain(*[kw.split(substring) for kw in lst_kw])) for lst_kw in keywords_lower]\n",
    "\n",
    "# for visualisation only (can remove later on)\n",
    "items_with_unsplit_keywords = get_items_with_substring(keywords_lower, substring)\n",
    "for i in range(4):\n",
    "    print('before:', keywords_lower[items_with_unsplit_keywords[i]])\n",
    "    print('after: ', keywords_lower_split[items_with_unsplit_keywords[i]], '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 3: remove unwanted characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '\\u2002' and '.', '\" ', '\"', 'keywords: ' (replace with empty)\n",
    "keywords_lower_split_clean = keywords_lower_split\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('\\u2002', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('.', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('\" ', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('\"', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('keywords: ', ''), lst_kw)) for lst_kw in keywords_lower_split_clean]\n",
    "\n",
    "# Replace '\\xa0' with space\n",
    "keywords_lower_split_clean = [list(map(lambda x: x.replace('\\xa0', ' '), lst_kw)) for lst_kw in keywords_lower_split_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['kraftwerk', 'electronic music', 'düsseldorf', 'autobahn', '\"autobahn\"', 'german music', 'germany', 'music']\n",
      "after:  ['kraftwerk', 'electronic music', 'düsseldorf', 'autobahn', 'autobahn', 'german music', 'germany', 'music'] \n",
      "\n",
      "before: ['united gipsy crew', 'nebud dilino', 'roma', 'czech republic', 'gypsies', 'education', '\"practical schools\" \"special schools\"']\n",
      "after:  ['united gipsy crew', 'nebud dilino', 'roma', 'czech republic', 'gypsies', 'education', 'practical schoolsspecial schools'] \n",
      "\n",
      "before: ['holocaust', '\"march of the living\"', 'auschwitz', 'shoa', 'germany', 'nazi', 'world war ii', 'concentration camps', 'history']\n",
      "after:  ['holocaust', 'march of the living', 'auschwitz', 'shoa', 'germany', 'nazi', 'world war ii', 'concentration camps', 'history'] \n",
      "\n",
      "before: ['art', 'artists', 'art market', 'self.marketing', 'art school', 'careers', 'living wage', '\"alles für die kunst', '\" arte', 'casting shows', 'reality tv']\n",
      "after:  ['art', 'artists', 'art market', 'selfmarketing', 'art school', 'careers', 'living wage', 'alles für die kunst', 'arte', 'casting shows', 'reality tv'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for visualisation only (can remove later on)\n",
    "items_with_unwanted_characters = get_items_with_substring(keywords_lower, substring = '\"')\n",
    "for i in range(4):\n",
    "    print('before:', keywords_lower_split[items_with_unwanted_characters[i]])\n",
    "    print('after: ', keywords_lower_split_clean[items_with_unwanted_characters[i]], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning 4: other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [i for i,lst_kw in enumerate(keywords_lower_split_clean) if any(list(map(lambda x: x.count(' ')>15, lst_kw)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as doctors', 'patrick', 'james and steve have little leisure time', \"so they're glad when they can watch a little football in peace and quiet at the weekend\"]\n",
      "['gmf14', 'ws1452', 'the power of the neighborhood: how local media organize participation and how dw akademie supports participatory approaches']\n",
      "['gmf14', 'ws1455', 'co-creating a new multimedia format with audiences – case study of el toque by radio netherlands worldwide']\n",
      "['de mistura is kerry lavrov lawrow united nations un syria russia us saudi arabia turkey iran qatar geneva peace talks']\n",
      "['oil glut: efforts to freeze global production unsuccessful - german-israel trade relations – contract extension: zetsche set to remain at daimler three more years']\n",
      "['germany has agreed to drastically cut subsidies that electricity companies will have to pay for solar power in the last decade', 'power firms have been obliged to pay more than the market rate certain solar power sources']\n",
      "['tomorrow today', 'deutsche welle', 'space', 'iss', 'the era of the nasa space shuttle is due to end in late 2010 after that', 'russian soyuz spacecraft will be the sole means of getting payloads to and from the iss space station new forms of transportation are needed see more on 3 may 2010']\n",
      "['cryosat', 'climat change', 'scientists are examining changes in the earth’s polar ice to learn more about the impact of climate change the surface area of these ice sheets are known', 'but researchers have been unable to precisely measure how thick they are a new satellite mission could help change that']\n",
      "['chilean post-doc raul angulo works at the max planck institute for astrophysics in garching studying the origins of galaxies']\n",
      "['dr frank jochum – adiposis – overweight children – obesity– body fat – heavy – chubby babies – body mass index']\n",
      "['prof eckard thiel – cancer – leukemia– tumor– stem cells – bone marrow – umbilical cord blood – tailored anti-cancer therapies – exercise and chemotherapy – immune system']\n",
      "['dr cora stefanie weber – psychosomatic – emotions and illness - physical memory – stress – mind and body – chronic pain']\n",
      "['why is the sea level of the pacific ocean higher than it is in the atlantic? einsteinchen', 'dvd']\n",
      "['taliban insurgents have struck at airport used by nato using heavy weaponry against the heavily defended compound no immediate details of casualties were available']\n",
      "['ccs climate change carbon capture and storage renewable energy power plant gas guzzler global warming iea climate protection']\n",
      "['allies of donald trump are set to challenge the election result in a longshot that is almost certain to fail']\n"
     ]
    }
   ],
   "source": [
    "for item in items: \n",
    "    print(keywords_lower_split_clean[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
