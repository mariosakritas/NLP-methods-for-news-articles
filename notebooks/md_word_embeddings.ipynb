{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/interim/clean_keywords_2019-01-01_2022-01-01.json'\n",
    "df = pd.read_json(filepath, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads word2vec google model\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words are represented with a vector of dimension:  300\n",
      "Number of words (vocabulary) in the model: 3000000\n",
      "Example of words: ['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']\n"
     ]
    }
   ],
   "source": [
    "print('Words are represented with a vector of dimension: ', wv.vector_size)\n",
    "print('Number of words (vocabulary) in the model:', len(wv))\n",
    "print('Example of words:', wv.index_to_key[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ['NASA', 'OSIRIS-REx', 'Bennu', 'asteroid']\n",
       "1    ['English Channel', 'migration', 'boats', 'ill...\n",
       "2    ['Brazil', 'Jair Bolsonaro', 'Chicago economic...\n",
       "Name: keywordStringsCleanAfterFuzz, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract keywords\n",
    "keywords_str = df['keywordStringsCleanAfterFuzz'][0:3].astype(str)\n",
    "keywords_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asteroid</th>\n",
       "      <th>bennu</th>\n",
       "      <th>boats</th>\n",
       "      <th>bolsonaro</th>\n",
       "      <th>brazil</th>\n",
       "      <th>channel</th>\n",
       "      <th>chicago</th>\n",
       "      <th>economics</th>\n",
       "      <th>english</th>\n",
       "      <th>guedes</th>\n",
       "      <th>hamilton</th>\n",
       "      <th>illegal</th>\n",
       "      <th>immigration</th>\n",
       "      <th>jair</th>\n",
       "      <th>migration</th>\n",
       "      <th>mourao</th>\n",
       "      <th>nasa</th>\n",
       "      <th>osiris</th>\n",
       "      <th>paulo</th>\n",
       "      <th>rex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asteroid  bennu  boats  bolsonaro  brazil  channel  chicago  economics  \\\n",
       "0         1      1      0          0       0        0        0          0   \n",
       "1         0      0      1          0       0        1        0          0   \n",
       "2         0      0      0          1       1        0        1          1   \n",
       "\n",
       "   english  guedes  hamilton  illegal  immigration  jair  migration  mourao  \\\n",
       "0        0       0         0        0            0     0          0       0   \n",
       "1        1       0         0        1            1     0          1       0   \n",
       "2        0       1         1        0            0     1          0       1   \n",
       "\n",
       "   nasa  osiris  paulo  rex  \n",
       "0     1       1      0    1  \n",
       "1     0       0      0    0  \n",
       "2     0       0      1    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the vectorizer \n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the model with our data (each keyword becomes a feature, some are split)\n",
    "X = vectorizer.fit_transform(keywords_str)\n",
    "\n",
    "# Make an array and fills it in\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Words in the vocabulary (some keywords are split)\n",
    "WordsVocab=CountVectorizedData.columns\n",
    "\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bennu\n",
      "osiris\n",
      "bolsonaro\n",
      "guedes\n",
      "jair\n",
      "mourao\n"
     ]
    }
   ],
   "source": [
    "# Creating empty dataframe to hold sentences\n",
    "W2Vec_Data=pd.DataFrame()\n",
    "\n",
    "# Looping through each row for the data\n",
    "for i in range(CountVectorizedData.shape[0]):\n",
    "\n",
    "    # initiating a sentence with all zeros\n",
    "    sentence = np.zeros(300)\n",
    "\n",
    "    # Looping thru each word in the sentence and if its present in \n",
    "    # the Word2Vec model then storing its vector\n",
    "    for word in WordsVocab[CountVectorizedData.iloc[i , :] >= 1]:\n",
    "        if word in wv.index_to_key:   \n",
    "            sentence = sentence + wv[word]\n",
    "        else:\n",
    "            print(word) \n",
    "    # Appending the sentence to the dataframe\n",
    "    W2Vec_Data = W2Vec_Data.append(pd.DataFrame([sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.182617</td>\n",
       "      <td>0.047119</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.589355</td>\n",
       "      <td>0.196259</td>\n",
       "      <td>-0.612854</td>\n",
       "      <td>0.220215</td>\n",
       "      <td>-0.068726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>-0.489746</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.023804</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>-0.420166</td>\n",
       "      <td>-0.286865</td>\n",
       "      <td>0.342285</td>\n",
       "      <td>0.759033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.154053</td>\n",
       "      <td>0.113770</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>-0.263184</td>\n",
       "      <td>-0.719360</td>\n",
       "      <td>-0.577271</td>\n",
       "      <td>-0.123596</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.320068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.215561</td>\n",
       "      <td>0.845909</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.254883</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>-0.284668</td>\n",
       "      <td>0.453857</td>\n",
       "      <td>0.143555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.426941</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>0.209290</td>\n",
       "      <td>1.017578</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.282715</td>\n",
       "      <td>-0.306396</td>\n",
       "      <td>-0.980957</td>\n",
       "      <td>-0.179443</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016602</td>\n",
       "      <td>0.634399</td>\n",
       "      <td>0.228271</td>\n",
       "      <td>0.607666</td>\n",
       "      <td>-0.173828</td>\n",
       "      <td>-0.103760</td>\n",
       "      <td>-0.198181</td>\n",
       "      <td>-1.099854</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>0.262787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.182617  0.047119  0.154297  0.467773 -0.137695 -0.589355  0.196259   \n",
       "0 -0.154053  0.113770  0.041992 -0.263184 -0.719360 -0.577271 -0.123596   \n",
       "0 -0.426941  0.242188  0.209290  1.017578  0.179688  0.282715 -0.306396   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.612854  0.220215 -0.068726  ...  0.154785  0.447266 -0.489746  0.336731   \n",
       "0  0.309570  0.201172  0.320068  ...  0.016357  0.215561  0.845909  0.062622   \n",
       "0 -0.980957 -0.179443  0.467773  ... -0.016602  0.634399  0.228271  0.607666   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.023804 -0.051758 -0.420166 -0.286865  0.342285  0.759033  \n",
       "0  0.300781  0.254883  0.032059 -0.284668  0.453857  0.143555  \n",
       "0 -0.173828 -0.103760 -0.198181 -1.099854 -0.002441  0.262787  \n",
       "\n",
       "[3 rows x 300 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2Vec_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lastModifiedDate</th>\n",
       "      <th>keywordStrings</th>\n",
       "      <th>keywordStringsCleanAfterFuzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46912921</td>\n",
       "      <td>2019-01-01T03:57:28.904Z</td>\n",
       "      <td>[NASA, OSIRIS-REx, Bennu, asteroid]</td>\n",
       "      <td>[NASA, OSIRIS-REx, Bennu, asteroid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46911356</td>\n",
       "      <td>2019-01-01T06:11:50.527Z</td>\n",
       "      <td>[English Channel, migration, boats, illegal im...</td>\n",
       "      <td>[English Channel, migration, boats, illegal im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46909694</td>\n",
       "      <td>2019-01-01T06:14:35.563Z</td>\n",
       "      <td>[Brazil, Jair Bolsonaro, Chicago economics, Ha...</td>\n",
       "      <td>[Brazil, Jair Bolsonaro, Chicago economics, Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46912694</td>\n",
       "      <td>2019-01-01T08:26:11.599Z</td>\n",
       "      <td>[Japan, Tokyo, Harajuku, attack]</td>\n",
       "      <td>[Japan, Tokyo, Harajuku, attack]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46910092</td>\n",
       "      <td>2019-01-01T09:05:00.736Z</td>\n",
       "      <td>[Asia, Bangladesh, elections, Kamal Hossain, S...</td>\n",
       "      <td>[Asia, Bangladesh, elections, Kamal Hossain, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33824</th>\n",
       "      <td>60304782</td>\n",
       "      <td>2021-12-31T18:47:57.479Z</td>\n",
       "      <td>[Putin, New Year, Coronavirus, Navalny, Ukraine]</td>\n",
       "      <td>[Putin, New Year, Coronavirus, Navalny, Ukraine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33825</th>\n",
       "      <td>60299904</td>\n",
       "      <td>2021-12-31T19:06:43.423Z</td>\n",
       "      <td>[Germany, Olaf Scholz, New Year, New Year's ad...</td>\n",
       "      <td>[Germany, Olaf Scholz, New Year, New Year's ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33826</th>\n",
       "      <td>60300458</td>\n",
       "      <td>2021-12-31T20:27:51.092Z</td>\n",
       "      <td>[Colorado, wildfires, Boulder County, evacuati...</td>\n",
       "      <td>[Colorado, wildfires, Boulder County, evacuati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33827</th>\n",
       "      <td>60267980</td>\n",
       "      <td>2021-12-31T20:32:20.303Z</td>\n",
       "      <td>[RCEP, Regional Comprehensive Economic Partner...</td>\n",
       "      <td>[RCEP, Regional Comprehensive Economic Partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33828</th>\n",
       "      <td>60304913</td>\n",
       "      <td>2021-12-31T20:38:11.201Z</td>\n",
       "      <td>[France, birth control, contraception, contrac...</td>\n",
       "      <td>[France, birth control, contraception, contrac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33829 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id          lastModifiedDate  \\\n",
       "0      46912921  2019-01-01T03:57:28.904Z   \n",
       "1      46911356  2019-01-01T06:11:50.527Z   \n",
       "2      46909694  2019-01-01T06:14:35.563Z   \n",
       "3      46912694  2019-01-01T08:26:11.599Z   \n",
       "4      46910092  2019-01-01T09:05:00.736Z   \n",
       "...         ...                       ...   \n",
       "33824  60304782  2021-12-31T18:47:57.479Z   \n",
       "33825  60299904  2021-12-31T19:06:43.423Z   \n",
       "33826  60300458  2021-12-31T20:27:51.092Z   \n",
       "33827  60267980  2021-12-31T20:32:20.303Z   \n",
       "33828  60304913  2021-12-31T20:38:11.201Z   \n",
       "\n",
       "                                          keywordStrings  \\\n",
       "0                    [NASA, OSIRIS-REx, Bennu, asteroid]   \n",
       "1      [English Channel, migration, boats, illegal im...   \n",
       "2      [Brazil, Jair Bolsonaro, Chicago economics, Ha...   \n",
       "3                       [Japan, Tokyo, Harajuku, attack]   \n",
       "4      [Asia, Bangladesh, elections, Kamal Hossain, S...   \n",
       "...                                                  ...   \n",
       "33824   [Putin, New Year, Coronavirus, Navalny, Ukraine]   \n",
       "33825  [Germany, Olaf Scholz, New Year, New Year's ad...   \n",
       "33826  [Colorado, wildfires, Boulder County, evacuati...   \n",
       "33827  [RCEP, Regional Comprehensive Economic Partner...   \n",
       "33828  [France, birth control, contraception, contrac...   \n",
       "\n",
       "                            keywordStringsCleanAfterFuzz  \n",
       "0                    [NASA, OSIRIS-REx, Bennu, asteroid]  \n",
       "1      [English Channel, migration, boats, illegal im...  \n",
       "2      [Brazil, Jair Bolsonaro, Chicago economics, Ha...  \n",
       "3                       [Japan, Tokyo, Harajuku, attack]  \n",
       "4      [Asia, Bangladesh, elections, Kamal Hossain, S...  \n",
       "...                                                  ...  \n",
       "33824   [Putin, New Year, Coronavirus, Navalny, Ukraine]  \n",
       "33825  [Germany, Olaf Scholz, New Year, New Year's ad...  \n",
       "33826  [Colorado, wildfires, Boulder County, evacuati...  \n",
       "33827  [RCEP, Regional Comprehensive Economic Partner...  \n",
       "33828  [France, birth control, contraception, contrac...  \n",
       "\n",
       "[33829 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
