{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "Loading data DONE. Number of articles is 175659\n",
      "Extracting data DONE. Number of articles from 2019-01-01 to 2022-01-01 is 33829\n",
      "Cleaning step 1 out of 2 DONE. Number of unique keywords went from 32682 to 30190\n",
      "Cleaning step 2 out of 2 DONE. Number of unique keywords went from 30190 to 27981\n",
      "Finished. Data stored in ../data/interim/clean_keywords_2019-01-01_2022-01-01.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "# Add src folder to the path\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from data.preprocess_keywords import make_cleaned_keywords_df\n",
    "from data.make_datasets import get_data\n",
    "\n",
    "# Specify wanted time range\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2022-01-01'\n",
    "\n",
    "# Path to data\n",
    "data_file = '../data/raw/CMS_2010_to_June_2022_ENGLISH.json'\n",
    "\n",
    "# Load and extract data within time range\n",
    "df_subset = get_data(data_file, start_date, end_date)\n",
    "\n",
    "# Cleans keywords and saves data as a dataframe\n",
    "make_cleaned_keywords_df(df_subset, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "filepath = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "df_loaded = pd.read_json(filepath, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify wanted time range\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2022-01-01'\n",
    "\n",
    "# Load data\n",
    "filepath = '../data/interim/clean_keywords_' + start_date + '_' + end_date + '.json'\n",
    "df_loaded = pd.read_json(filepath, orient ='split', compression = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocess_keywords import get_items_with_substring\n",
    "\n",
    "substring = \"I'm\"\n",
    "lst_lst_keywords = df_loaded['keywordStringsCleanAfterFuzz']\n",
    "\n",
    "indices_substring, lst_keywords_substring, keywords_substring = get_items_with_substring(lst_lst_keywords, substring)\n",
    "\n",
    "for ind, lst_kw in zip(indices_substring, lst_keywords_substring):\n",
    "    print(ind, lst_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_lst_keywords_clean = [list(map(lambda x: x.strip(), lst_kw)) for lst_kw in lst_lst_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turkey', '2016 turkey coup', 'recep tayyip erdogan', 'fethullah gulen', 'military coup']\n",
      "['turkey', 'germany', 'deniz y√ºcel', 'journalism', 'reporters without borders', 'freedom of the press', 'recep tayyip erdogan', 'constitutional court of turkey']\n",
      "['conflict', 'syria turkey', 'drones', 'uav', 'turkey ministry of defence']\n",
      "['eu turkey', 'refugees', 'asylum', 'deportation', 'settlements']\n",
      "['reception', 'turkey', 'dw', 'reception turkey', 'cable partner', 'cable provider', 'satellite', 'live stream']\n",
      "[\"women's rights\", \"women's rights turkey\", 'turkey women', 'turkey', 'las tesis', 'the rapist is you']\n",
      "['eu migrant crisis', 'migration', 'italy', 'spain', 'greece', 'malta', 'cyprus', 'eu turkey migrant pact']\n",
      "['greek independence', 'ottoman turkey', 'athens', 'battle of navarino', 'kyriakos mitsotakis']\n",
      "['2016 turkey coup', 'turkey', 'erdogan']\n",
      "['fred lumbuye', 'ugandan media', 'president yoweri museveni', 'online censorship', 'digital censorship turkey']\n",
      "['greece', 'migrant crisis', 'samos', 'migrants turkey eu border', 'refugees']\n",
      "['angela merkel', 'recep tayyip erdogan', 'eu turkey migrant pact', 'turkey eu accession talks']\n"
     ]
    }
   ],
   "source": [
    "indices_substring, lst_keywords_substring, keywords_substring = get_items_with_substring(lst_lst_keywords_clean, substring)\n",
    "\n",
    "for lst_kw in lst_keywords_substring:\n",
    "    print(lst_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
